<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <link rel="icon" href="favicon.ico" sizes="any" />
  <link rel="icon" type="image/svg+xml" href="favicon.svg" />
  <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">
  <title>MCBAISE • PALE REGARD • ABSURDIA FANTASMAGORIA</title>
  <script>
    // vizOnly iframes should never show the YouTube pane/loading UI.
    // Do this in the head to avoid a flash before the module script runs.
    try {
      const p = new URLSearchParams(location.search);
      if (p.get('vizOnly') === '1') document.documentElement.classList.add('vizOnly');
      // Debug flag via query string: ?debug will enable verbose instrumentation.
      const DEBUG_MCBAISE = p.get('debug') === '1' || p.get('debug') === 'true' || p.has('debug');
      // Expose for other scripts
      window.__MCBAISE_DEBUG = !!DEBUG_MCBAISE;
      // If debug is not enabled, silence all console output to avoid noisy
      // logs during normal usage and profiling. When debug is enabled, restore
      // original console methods.
      try {
        const _orig = {
          log: console.log && console.log.bind(console),
          info: console.info && console.info.bind(console),
          warn: console.warn && console.warn.bind(console),
          error: console.error && console.error.bind(console),
          debug: console.debug && console.debug.bind(console),
        };
        // Always keep warn/error available so runtime issues surface.
        try { if (_orig.warn) console.warn = _orig.warn; } catch (_) {}
        try { if (_orig.error) console.error = _orig.error; } catch (_) {}

        // Wrap log/info/debug so they only emit when our debug flag is set.
        const guarded = (orig) => function(...args) {
          try {
            if (window.__MCBAISE_DEBUG) return orig && orig(...args);
          } catch (_) {}
        };
        try { console.log = guarded(_orig.log); } catch (_) {}
        try { console.info = guarded(_orig.info); } catch (_) {}
        try { console.debug = guarded(_orig.debug || _orig.log); } catch (_) {}
      } catch (_) {}
      // Notify the service worker to enable debug logs when requested.
      try {
        if (window.__MCBAISE_DEBUG && 'serviceWorker' in navigator) {
          try {
            // Prefer the active worker if ready.
            navigator.serviceWorker.ready.then(reg => {
              try { reg.active?.postMessage?.({ type: 'SW_DEBUG_ENABLE' }); } catch (_) {}
            }).catch(() => {});
            // Also attempt direct controller postMessage (if available earlier).
            try { navigator.serviceWorker.controller?.postMessage?.({ type: 'SW_DEBUG_ENABLE' }); } catch (_) {}
          } catch (_) {}
        }
      } catch (_) {}

      // Long task observer: log heavy tasks when debug enabled.
      try {
        if (typeof PerformanceObserver !== 'undefined') {
          const po = new PerformanceObserver((list) => {
            if (!window.__MCBAISE_DEBUG) return;
            for (const e of list.getEntries()) {
              try {
                if (e.duration && e.duration > 50) console.warn('mcbaise:longtask', { name: e.name, duration: e.duration, entry: e });
              } catch (_) {}
            }
          });
          try { po.observe({ type: 'longtask', buffered: true }); } catch (_) {}
        }
      } catch (_) {}
    } catch (_) {}
  </script>
  <script>
    // Chrome warns when a non-passive `touchstart` listener is attached because it
    // can block scrolling. On wasm, winit installs touch listeners on the canvas
    // during window creation via wasm-bindgen glue, which triggers this warning.
    //
    // We don't want the page to scroll/overscroll while interacting with the viz.
    // We achieve that via CSS `touch-action` (below), so the listeners can be
    // safely marked passive.
    try {
      const origAdd = EventTarget.prototype.addEventListener;
      EventTarget.prototype.addEventListener = function(type, listener, options) {
        try {
          if ((type === 'touchstart' || type === 'touchmove') && this instanceof HTMLCanvasElement) {
            const canvas = this;
            if (canvas.id === 'bevy-canvas') {
              if (options === undefined || options === false) {
                options = { passive: true };
              } else if (options === true) {
                options = { capture: true, passive: true };
              } else if (typeof options === 'object' && options && options.passive !== true) {
                options = { ...options, passive: true };
              }
            }
          }
        } catch (_) {}
        return origAdd.call(this, type, listener, options);
      };
    } catch (_) {}
  </script>
  <style>
    @import url("https://fonts.googleapis.com/css2?family=Baloo+2:wght@700;800&display=swap");

    html, body {
      margin: 0;
      height: 100%;
      overflow: hidden;
      overscroll-behavior: none;
      background: #000;
      font-family: system-ui, sans-serif;
    }

    /* Prevent browser touch panning/zooming on the Bevy canvas so touch listeners
       can be passive without reintroducing scroll jank. */
    #bevy-canvas {
      touch-action: none;
    }

    #root { height: 100%; display: flex; }

    /* vizOnly iframes: hide the YouTube pane entirely (no flash). */
    .vizOnly #left { display: none !important; }
    .vizOnly #ytLoading,
    .vizOnly #playerWrap,
     /* vizOnly: don't hide the cardinal pi container — viz-only frames shouldn't show the player, but
       the control overlay must remain usable when present in the parent document. */

    /*
      vizOnly iframes: make the viz pane fill the iframe viewport deterministically.
      This avoids edge-cases where Bevy's `fit_canvas_to_parent` observes a 0-sized parent
      during early layout and never resizes.
    */
    .vizOnly #right { position: fixed; inset: 0; }

    /* vizOnly: do not show captions; credits are allowed. */
    .vizOnly #caption { display: none !important; }

    #left, #right {
      flex: 1;
      position: relative;
      min-width: 0;
    }

    #left {
      border-right: 2px solid rgba(255,255,255,0.12);
      background: #000;
      display: flex;
      flex-direction: column;
      min-height: 0;
    }

    /* Landscape: hide video by collapsing width. */
    #root.hideVideo #left {
      flex: 0 0 0px;
      width: 0px;
      border-right: 0;
    }

    /* Portrait (more tall than wide): stack vertically (video above, viz below). */
    @media (max-aspect-ratio: 1/1) {
      #root { flex-direction: column; }

      #left {
        border-right: 0;
        border-bottom: 2px solid rgba(255,255,255,0.12);
      }

      /* Give the video a reasonable default height in portrait. */
      #left { flex: 0 0 40%; }
      #right { flex: 1 1 auto; }

      /* If extra viz panes are present in portrait, don't force the video column
        to a fixed 40% height. Split space evenly so injected N/S panes have
        room to fill and don't collapse to tiny strips. */
      #root.hasPortraitExtras #left { flex: 1 1 50%; }
      #root.hasPortraitExtras #right { flex: 1 1 50%; }

      /* Portrait: hide video by collapsing height. */
      #root.hideVideo #left {
        flex: 0 0 0px;
        height: 0px;
        width: auto;
        border-bottom: 0;
      }
    }

    #playerWrap {
      position: relative;
      flex: 1 1 auto;
      min-height: 0;
      background: #000;
      isolation: isolate;
    }
    /* When hiding video we only hide the player contents, not the entire left column,
       so viz panes inserted above/below remain present. */
     /* hide only the player contents and collapse the player area so it doesn't
       take vertical space between N and S viz panes */
     #playerWrap.hidePlayer { flex: 0 0 0px; height: 0px; min-height: 0; overflow: hidden; padding: 0; }
     #playerWrap.hidePlayer #player { display: none !important; }
     #playerWrap.hidePlayer #ytLoading { display: none !important; }
    #player { position: absolute; inset: 0; width: 100%; height: 100%; z-index: 1; }
    #player iframe { width: 100% !important; height: 100% !important; display: block; }

    /* Legacy single-π CSS removed; use the cardinal buttons in #videoPiContainer. */

    /* container for the 4 cardinal π buttons: top-level fixed overlay so it's always on top */
    #videoPiContainer { position: fixed; inset: 0; pointer-events: none; z-index: 100000; }
    .videoPi {
      position: absolute;
      width: 34px;
      height: 34px;
      display: grid;
      place-items: center;
      border-radius: 8px;
      border: 1.2px solid rgba(255,255,255,0.65);
      background: rgba(0,0,0,0.15);
      color: rgba(255,255,255,0.95);
      font-weight: 800;
      cursor: pointer;
      pointer-events: auto;
      z-index: 40;
    }
    .videoPi[data-dir="top"] { left: 50%; transform: translateX(-50%); top: calc(env(safe-area-inset-top, 0px) + 8px); }
    .videoPi[data-dir="bottom"] { left: 50%; transform: translateX(-50%); bottom: calc(env(safe-area-inset-bottom, 0px) + 8px); }
    .videoPi[data-dir="left"] { left: 8px; top: 50%; transform: translateY(-50%); }
    .videoPi[data-dir="right"] { right: 8px; top: 50%; transform: translateY(-50%); }

    /* Recorder buttons: same outline style as E/W, positioned above them. */
    .videoPiRecord {
      font-family: 'Material Icons';
      font-weight: 400;
      font-size: 22px;
      line-height: 1;
      user-select: none;
    }
    .videoPiRecord[data-pos="left-above"] { left: 8px; top: calc(50% - 44px); transform: translateY(-50%); }
    .videoPiRecord[data-pos="right-above"] { right: 8px; top: calc(50% - 44px); transform: translateY(-50%); }

    /* Encoding overlay */
    #encodeOverlay {
      position: fixed;
      inset: 0;
      display: none;
      place-items: center;
      pointer-events: auto;
      z-index: 100001;
      background: rgba(0,0,0,0.55);
      backdrop-filter: blur(6px);
    }
    #encodeOverlay.show { display: grid; }
    #encodeOverlay .box {
      width: min(92vw, 520px);
      border-radius: 14px;
      border: 1px solid rgba(255,255,255,0.20);
      background: rgba(0,0,0,0.70);
      padding: 14px 14px 12px;
      color: rgba(255,255,255,0.92);
      box-shadow: 0 10px 26px rgba(0,0,0,0.35);
    }
    #encodeOverlay .hdr {
      font: 800 18px/1.05 "Baloo 2", system-ui, sans-serif;
      letter-spacing: 0.02em;
      margin-bottom: 8px;
    }
    #encodeOverlay .msg {
      font: 600 13px/1.35 system-ui, sans-serif;
      opacity: 0.9;
      margin-bottom: 10px;
    }
    #encodeOverlay .bar {
      height: 8px;
      border-radius: 999px;
      border: 1px solid rgba(255,255,255,0.25);
      background: rgba(0,0,0,0.25);
      overflow: hidden;
      margin-bottom: 12px;
    }
    #encodeOverlay .bar > div {
      height: 100%;
      width: 0%;
      background: rgba(255,255,255,0.65);
    }
    #encodeOverlay .actions {
      display: flex;
      justify-content: flex-end;
      gap: 10px;
    }
    #encodeOverlayStop {
      appearance: none;
      border: 1.2px solid rgba(255,255,255,0.65);
      border-radius: 10px;
      background: rgba(0,0,0,0.15);
      color: rgba(255,255,255,0.95);
      padding: 8px 12px;
      font: 800 12px/1 system-ui, sans-serif;
      cursor: pointer;
    }
    #encodeOverlayStop:active { transform: translateY(1px); }

    /* hidden by default; toggled by .show on container */
    #videoPiContainer { opacity: 0; transition: opacity 140ms ease; }
    #videoPiContainer.show { opacity: 1; }

    .extraViz {
      flex: 1 1 0px;
      position: relative;
      min-width: 0;
      min-height: 0;
      background: #000;
    }

    .extraViz iframe {
      position: absolute;
      inset: 0;
      width: 100%;
      height: 100%;
      border: 0;
      display: block;
    }

    #ytLoading {
      position: absolute;
      inset: 0;
      display: grid;
      place-items: center;
      pointer-events: none;
      background: rgba(0,0,0,0.55);
      backdrop-filter: blur(6px);
      opacity: 0;
      transition: opacity 200ms ease;
      z-index: 5;
    }

    #ytLoading.show { opacity: 1; }

    #viz { position: absolute; inset: 0; }
    #bevy-canvas { position: absolute; inset: 0; width: 100%; height: 100%; display: block; }

    #overlay {
      position: absolute;
      inset: 0;
      pointer-events: none;
      display: grid;
      grid-template-rows: 1fr auto 1fr;
      align-items: center;
      justify-items: center;
      padding: 4vmin;
    }

    /* Debug toast (used to confirm key chords are being detected). */
    #keyToast {
      position: fixed;
      right: 10px;
      top: 10px;
      z-index: 10000;
      pointer-events: none;
      opacity: 0;
      transform: translateY(-6px);
      transition: opacity 120ms ease, transform 120ms ease;
      padding: 6px 9px;
      border-radius: 8px;
      border: 1px solid rgba(255,255,255,0.35);
      color: rgba(255,255,255,0.92);
      background: rgba(0,0,0,0.65);
      font: 600 12px/1.25 system-ui, sans-serif;
      letter-spacing: 0.01em;
      white-space: nowrap;
    }

    #keyToast.show {
      opacity: 1;
      transform: translateY(0);
    }

    .title {
      grid-row: 2;
      text-align: center;
      font-family: "Baloo 2", system-ui, sans-serif;
      font-weight: 800;
      letter-spacing: 0.02em;
      line-height: 0.95;
      color: #F2B100;
      text-shadow:
        0 2px 0 rgba(0,0,0,0.35),
        0 10px 26px rgba(0,0,0,0.35);
      opacity: 0;
      transform: translateY(12px) scale(0.98);
      transition: opacity 260ms ease, transform 260ms ease;
      filter: saturate(1.15);
    }

    .title.show {
      opacity: 1;
      transform: translateY(0) scale(1);
    }

    .title.wobble {
      animation: wobble 1.35s ease-in-out infinite;
    }

    @keyframes wobble {
      0%   { transform: translateY(0) scale(1) skewX(0deg); }
      25%  { transform: translateY(-1px) scale(1.01) skewX(-0.7deg); }
      50%  { transform: translateY(0) scale(1) skewX(0.7deg); }
      75%  { transform: translateY(1px) scale(0.995) skewX(-0.4deg); }
      100% { transform: translateY(0) scale(1) skewX(0deg); }
    }

    .caption {
      grid-row: 3;
      width: min(92%, 900px);
      text-align: center;
      font-size: clamp(16px, 2.2vw, 26px);
      line-height: 1.25;
      color: rgba(255,255,255,0.94);
      text-shadow: 0 2px 10px rgba(0,0,0,0.55);
      padding: 10px 14px;
      border-radius: 14px;
      background: linear-gradient(to bottom, rgba(0,0,0,0.30), rgba(0,0,0,0.12));
      backdrop-filter: blur(4px);
      opacity: 0;
      transform: translateY(8px);
      transition: opacity 180ms ease, transform 180ms ease;
    }

    .caption.show {
      opacity: 1;
      transform: translateY(0);
    }

    .caption.meta {
      opacity: 0.55;
      font-style: italic;
    }

    #loading {
      position: absolute;
      inset: 0;
      display: grid;
      place-items: center;
      pointer-events: none;
      background: rgba(0,0,0,0.70);
      backdrop-filter: blur(6px);
      opacity: 0;
      transition: opacity 200ms ease;
      z-index: 10;
    }

    #loading.show {
      opacity: 1;
    }

    #loading .box {
      width: min(92vw, 640px);
      padding: 18px 18px;
      border-radius: 14px;
      background: rgba(0,0,0,0.55);
      border: 1px solid rgba(255,255,255,0.12);
      color: rgba(255,255,255,0.92);
      text-align: center;
      line-height: 1.25;
    }

    #loading .title {
      font-family: "Baloo 2", system-ui, sans-serif;
      font-weight: 800;
      letter-spacing: 0.02em;
      color: #F2B100;
      margin-bottom: 8px;
      font-size: 22px;
    }

    #loading .msg {
      font-size: 16px;
      opacity: 0.9;
    }

    #ytLoading .box {
      width: min(92vw, 520px);
      padding: 16px 16px;
      border-radius: 14px;
      background: rgba(0,0,0,0.55);
      border: 1px solid rgba(255,255,255,0.12);
      color: rgba(255,255,255,0.92);
      text-align: center;
      line-height: 1.25;
    }

    #ytLoading .title {
      font-family: "Baloo 2", system-ui, sans-serif;
      font-weight: 800;
      letter-spacing: 0.02em;
      color: #F2B100;
      margin-bottom: 6px;
      font-size: 20px;
    }

    #ytLoading .msg {
      font-size: 15px;
      opacity: 0.9;
    }

  /* controls removed — use egui overlay from wasm instead */
  </style>
</head>
<body>
  <div id="root">
    <div id="left">
      <div id="playerWrap">
        <div id="player"></div>

        <!-- videoPiContainer moved to top-level (inserted after #root) -->

        <div id="ytLoading" class="show">
          <div class="box">
            <div class="title">Loading YouTube…</div>
            <div class="msg" id="ytLoadingMsg">Preparing the player…</div>
          </div>
        </div>
      </div>
    </div>

    <div id="right">
      <div id="viz">
        <canvas id="bevy-canvas"></canvas>
      </div>

      <div id="loading" class="show">
        <div class="box">
          <div class="title">Hold on…</div>
          <div class="msg" id="loadingMsg">Loading the app (the model is large; this can take a moment)…</div>
        </div>
      </div>

      <div id="overlay">
        <div class="title" id="credit"></div>
        <div class="caption" id="caption"></div>
      </div>

  <!-- DOM controls removed — interactive UI is provided by Egui overlay inside the wasm app -->
    </div>
  </div>

  <!-- Top-level cardinal π container: always fixed above all content. -->
  <div id="videoPiContainer" aria-hidden="true">
    <button class="videoPi" data-dir="top" title="Add viz above">N</button>
    <button class="videoPi" data-dir="right" title="Add viz right">E</button>
    <button class="videoPi" data-dir="bottom" title="Add viz below">S</button>
    <button class="videoPi" data-dir="left" title="Add viz left">W</button>
    <!-- Recorder buttons (above W and E) -->
    <button id="videoSingle" class="videoPi videoPiRecord" data-pos="left-above" title="Record (single canvas)">videocam</button>
    <button id="videoFullscreen" class="videoPi videoPiRecord" data-pos="right-above" title="Record (fullscreen composite)">web</button>
  </div>

  <!-- Encoding overlay: shown while GIF/WebM encoding is running. -->
  <div id="encodeOverlay" aria-hidden="true">
    <div class="box">
      <div class="hdr" id="encodeOverlayHdr">Encoding…</div>
      <div class="msg" id="encodeOverlayMsg">Preparing…</div>
      <div class="bar"><div id="encodeOverlayBar"></div></div>
      <div class="actions">
        <button id="encodeOverlayStop" type="button">Stop</button>
      </div>
    </div>
  </div>

  <script type="module">
    const VIDEO_ID = "v2hcW03gcus";
    const PROJECT_NAME = "bevy_Mcbaise_Pale_Regard_Absurdia_Fantasmagoria";
    // Export globals for non-module scripts (recorder, debug helpers)
    try { window.VIDEO_ID = VIDEO_ID; } catch (_) {}
    try { window.PROJECT_NAME = PROJECT_NAME; } catch (_) {}
    function getOutputFilename(ext) {
      try {
        const t = new Date().toISOString().replace(/[:.]/g, '-');
        return `${PROJECT_NAME}-${t}.${ext}`;
      } catch (_) { return `bevy-recording.${ext}`; }
    }
    try { window.getOutputFilename = getOutputFilename; } catch (_) {}

    const params = new URLSearchParams(window.location.search);
    const vizOnly = params.get("vizOnly") === "1";

    const creditEl = document.getElementById("credit");
    const captionEl = document.getElementById("caption");
    const rootEl = document.getElementById("root");
    const loadingEl = document.getElementById("loading");
    const loadingMsgEl = document.getElementById("loadingMsg");
    const ytLoadingEl = document.getElementById("ytLoading");
    const ytLoadingMsgEl = document.getElementById("ytLoadingMsg");
    const videoPiContainer = document.getElementById("videoPiContainer");
    const playerWrapEl = document.getElementById("playerWrap");
    const PAGE_ORIGIN = window.location.origin;

    // Let wasm egui receive right-clicks: prevent the browser context menu on the canvas.
    try {
      const bevyCanvas = document.getElementById("bevy-canvas");
      if (bevyCanvas) {
        bevyCanvas.addEventListener("contextmenu", (e) => {
          try { e.preventDefault(); } catch (_) {}
          return false;
        });
      }
    } catch (_) {}

    // Small toast to confirm key detection (useful when DevTools shortcuts are blocked).
    const keyToastEl = (() => {
      const el = document.createElement("div");
      el.id = "keyToast";
      el.textContent = "";
      document.body.appendChild(el);
      return el;
    })();

    let keyToastTimer = null;
    function showKeyToast(text) {
      if (!keyToastEl) return;
      keyToastEl.textContent = text;
      keyToastEl.classList.add("show");
      if (keyToastTimer) clearTimeout(keyToastTimer);
      keyToastTimer = setTimeout(() => keyToastEl.classList.remove("show"), 900);
    }

    // Two-step devtools helper: first press focuses the page, second press triggers `debugger;`.
    let devtoolsChordPrimedUntilMs = 0;
    function focusForDevtools() {
      // Make sure our targets can be focused programmatically.
      // (tabIndex=-1 keeps them out of normal tab order.)
      try {
        rootEl.tabIndex = -1;
      } catch (_) {}
      const playerWrapEl = document.getElementById("playerWrap");
      try {
        if (playerWrapEl) playerWrapEl.tabIndex = -1;
      } catch (_) {}

      // Ask the window/document to focus, then focus a stable element.
      try {
        window.focus();
      } catch (_) {}
      try {
        rootEl.focus({ preventScroll: true });
      } catch (_) {
        try {
          rootEl.focus();
        } catch (_) {}
      }

      // If we're not in vizOnly, also try focusing the player wrapper.
      if (!vizOnly && playerWrapEl) {
        try {
          playerWrapEl.focus({ preventScroll: true });
        } catch (_) {
          try {
            playerWrapEl.focus();
          } catch (_) {}
        }
      }
    }

    // Best-effort: some embedded hosts (or focus states) may not open DevTools with Ctrl+Shift+I.
    // Browsers do not expose an API to open DevTools directly, but a `debugger` statement often
    // prompts DevTools to open when available.
    window.addEventListener(
      "keydown",
      (e) => {
        if ((e.ctrlKey || e.metaKey) && e.shiftKey && (e.key === "I" || e.key === "i")) {
          // Do not preventDefault() here: in real browsers this is a built-in DevTools shortcut.
          const now = Date.now();
          if (now <= devtoolsChordPrimedUntilMs) {
            showKeyToast("Ctrl+Shift+I again (debugger)");
            debugger;
          } else {
            devtoolsChordPrimedUntilMs = now + 2000;
            focusForDevtools();
            showKeyToast("Ctrl+Shift+I (focused) — press again");
          }
        }
      },
      { capture: true }
    );

    // Ctrl/Cmd+D toggles MCBAISE debug mode (lightweight). Note: this
    // overrides the browser's default bookmark shortcut. It persists the
    // choice to localStorage and notifies the service worker.
    function setDebugEnabled(enabled) {
      try {
        window.__MCBAISE_DEBUG = !!enabled;
        try { localStorage.setItem('mcbaise_debug', window.__MCBAISE_DEBUG ? '1' : '0'); } catch (_) {}
        // Notify SW
        try {
          if ('serviceWorker' in navigator) {
            navigator.serviceWorker.ready.then(reg => { try { reg.active?.postMessage?.({ type: window.__MCBAISE_DEBUG ? 'SW_DEBUG_ENABLE' : 'SW_DEBUG_DISABLE' }); } catch (_) {} }).catch(() => {});
            try { navigator.serviceWorker.controller?.postMessage?.({ type: window.__MCBAISE_DEBUG ? 'SW_DEBUG_ENABLE' : 'SW_DEBUG_DISABLE' }); } catch (_) {}
          }
        } catch (_) {}
        try { showKeyToast(window.__MCBAISE_DEBUG ? 'Debug ON' : 'Debug OFF'); } catch (_) {}
      } catch (_) {}
    }

    function toggleDebug() { setDebugEnabled(!window.__MCBAISE_DEBUG); }

    window.addEventListener('keydown', (e) => {
      try {
        if ((e.ctrlKey || e.metaKey) && !e.shiftKey && (e.key === 'd' || e.key === 'D')) {
          // Prevent default browser action (bookmark) only when we successfully toggle
          try { e.preventDefault(); } catch (_) {}
          toggleDebug();
        }
      } catch (_) {}
    }, { capture: true });

    // Respect persisted debug setting if querystring didn't explicitly enable debug.
    try {
      if (!window.__MCBAISE_DEBUG) {
        try {
          const s = localStorage.getItem('mcbaise_debug');
          if (s === '1') {
            setDebugEnabled(true);
          }
        } catch (_) {}
      }
    } catch (_) {}

    let wasmReady = false;
    let ytReady = false;
    let bootFailed = false;

    function setVideoPiVisible(show) {
      if (!videoPiContainer) return;
      videoPiContainer.classList.toggle("show", !!show);

      // Keep accessibility state consistent with visibility.
      // If we hide while a button inside retains focus, Chromium will warn and
      // ignore `aria-hidden`. Blur first, then apply `inert` to prevent focus.
      try {
        const hidden = !show;
        const active = document.activeElement;
        if (hidden && active && videoPiContainer.contains(active) && typeof active.blur === 'function') {
          try { active.blur(); } catch (_) {}
        }

        // Prefer `inert` (prevents both focus and pointer events).
        if (hidden) {
          try { videoPiContainer.setAttribute('aria-hidden', 'true'); } catch (_) {}
          try { videoPiContainer.inert = true; } catch (_) { try { videoPiContainer.setAttribute('inert', ''); } catch (_) {} }
        } else {
          try { videoPiContainer.setAttribute('aria-hidden', 'false'); } catch (_) {}
          try { videoPiContainer.inert = false; } catch (_) { try { videoPiContainer.removeAttribute('inert'); } catch (_) {} }
        }
      } catch (_) {}
    }

    function setVizLoading(show, text) {
      loadingEl.classList.toggle("show", !!show);
      if (typeof text === "string" && text.length && loadingMsgEl) {
        loadingMsgEl.textContent = text;
      }
    }

    function setYoutubeLoading(show, text) {
      ytLoadingEl.classList.toggle("show", !!show);
      if (typeof text === "string" && text.length && ytLoadingMsgEl) {
        ytLoadingMsgEl.textContent = text;
      }
    }

    function refreshLoading() {
      // Only show the DOM π control when both halves are ready.
      // (And never in vizOnly iframes.)
      console.debug('refreshLoading:', { vizOnly, bootFailed, wasmReady, ytReady });
      setVideoPiVisible(!vizOnly && !bootFailed && wasmReady && ytReady);

      if (bootFailed) {
        setVizLoading(true, "Failed to load the app. Check the console for details.");
        if (!vizOnly) setYoutubeLoading(true, "YouTube may also fail to load.");
        return;
      }

      // By default, keep the overlays in a sane state.
      if (!wasmReady) {
        // If the caller provided a more specific message, it will already be set via setVizLoading().
        setVizLoading(true, loadingMsgEl?.textContent || "Loading…");
      } else {
        setVizLoading(false, "");
      }

      if (vizOnly) {
        setYoutubeLoading(false, "");
      } else if (!ytReady) {
        setYoutubeLoading(true, ytLoadingMsgEl?.textContent || "Loading YouTube…");
      } else {
        setYoutubeLoading(false, "");
      }
    }

    // Called from Rust (wasm) to show/hide the YouTube pane.
    // "Hide" means collapse the left column to 0 width.
    globalThis.mcbaise_set_video_visible = (show) => {
      if (vizOnly) {
        // Forward to parent: only the parent actually owns the YouTube pane.
        try {
          window.parent?.postMessage({ type: "mcbaise_set_video_visible", show: !!show }, PAGE_ORIGIN);
        } catch (_) {}
        return;
      }
      setVideoVisibility(!!show);
    };

    // Loading overlay control. Called both from JS boot and from Rust (wasm) once ready.
    // Back-compat: still allow wasm/JS to control the viz overlay directly.
    globalThis.mcbaise_set_loading = (show, text) => setVizLoading(show, text);

    // Called from Rust (wasm) to update overlays.
    // Keep signature tolerant: some builds pass (html, show) and (text, show, isMeta).
    globalThis.mcbaise_set_credit = (...args) => {
      try {
        // Typical: (html, show)
        const html = (args.length >= 1 && args[0] != null) ? String(args[0]) : '';
        const show = (args.length >= 2) ? !!args[1] : !!html;
        if (!creditEl) return;
        if (!show) {
          try { creditEl.classList.remove('show', 'wobble'); } catch (_) {}
          try { creditEl.innerHTML = ''; } catch (_) {}
          return;
        }
        try { creditEl.innerHTML = html; } catch (_) { creditEl.textContent = html; }
        try { creditEl.classList.add('show', 'wobble'); } catch (_) {}
      } catch (_) {}
    };

    globalThis.mcbaise_set_caption = (...args) => {
      try {
        // Typical: (text, show, isMeta)
        const text = (args.length >= 1 && args[0] != null) ? String(args[0]) : '';
        const show = (args.length >= 2) ? !!args[1] : !!text;
        const isMeta = (args.length >= 3) ? !!args[2] : false;

        if (!captionEl) return;

        if (vizOnly) {
          // vizOnly iframes: captions are hidden by default.
          try { captionEl.classList.remove('show', 'meta'); } catch (_) {}
          try { captionEl.textContent = ''; } catch (_) {}
          return;
        }

        if (!show) {
          try { captionEl.classList.remove('show', 'meta'); } catch (_) {}
          try { captionEl.textContent = ''; } catch (_) {}
          return;
        }

        captionEl.textContent = text;
        captionEl.classList.add('show');
        captionEl.classList.toggle('meta', !!isMeta);

        // Nudge child frames when captions change — this can unstick throttled
        // or backgrounded iframes in some UAs. Best-effort authoritative sync.
        try {
          const t = playerReady ? (player?.getCurrentTime?.() ?? 0) : 0;
          try { broadcastSync(t, !!isPlaying); } catch (_) {}
        } catch (_) {}

        // Ask parent for a targeted authoritative sync now that wasm is ready.
        try {
          if (typeof globalThis.mcbaise_child_request_sync === 'function') {
            try { globalThis.mcbaise_child_request_sync(); } catch (_) {}
          } else {
            try { window.parent?.postMessage?.({ type: 'child_watchdog_request_sync' }, PAGE_ORIGIN); } catch (_) {}
          }
        } catch (_) {}
      } catch (_) {}
    };

    // Called from Rust (wasm) once the startup scene has been created.
    globalThis.mcbaise_set_wasm_ready = () => {
      wasmReady = true;
      refreshLoading();
      // If this is a viz-only iframe, notify the parent (or transferred port) that
      // we're ready to provide snapshots. This helps the parent avoid requesting
      // snapshots before the canvas exists.
      try {
        const msg = { type: 'snapshot_ready' };
        try { childPort?.postMessage?.(msg); } catch (_) { window.parent?.postMessage?.(msg, PAGE_ORIGIN); }
      } catch (_) {}
    };

    function loadScript(src) {
      return new Promise((resolve, reject) => {
        const s = document.createElement("script");
        s.src = src;
        s.async = true;
        s.onload = resolve;
        s.onerror = reject;
        document.head.appendChild(s);
      });
    }

    // Boot wasm.
    let wasm = null;

    // Debug helper: log any wasm readback messages arriving via postMessage.
    // This helps diagnose cases where iframes never deliver `wasm_pixels`.
    try {
      if (window.__MCBAISE_DEBUG && !window._mcbaise_debug_wasm_msg_listener_installed) {
        window._mcbaise_debug_wasm_msg_listener_installed = true;
        window.addEventListener('message', (ev) => {
          try {
            const d = ev && ev.data;
            if (!d || typeof d !== 'object') return;
            if (d.type !== 'wasm_pixels' && d.type !== 'wasm_imagebitmap' && d.type !== 'snapshot_gpu_triggered') return;
            const fromOtherWindow = !!(ev.source && ev.source !== window);
            console.debug('mcbaise:debug:window_message', {
              type: d.type,
              origin: ev.origin,
              fromOtherWindow,
              w: d.width,
              h: d.height,
              gpu: d.gpu,
              checksum: d.checksum,
              hasPixels: !!d.pixels,
              hasBitmap: !!d.bitmap,
              syncId: d.syncId,
              timeSec: d.timeSec,
            });
            try { window._mcbaise_last_debug_wasm_msg = { atMs: performance.now(), origin: ev.origin, fromOtherWindow, data: d }; } catch (_) {}
          } catch (_) {}
        });
      }
    } catch (_) {}

    async function bootWasm() {
      wasmReady = false;
      bootFailed = false;
      refreshLoading();
      // Bust cache for both the JS glue and the wasm binary.
      // This prevents running an older cached glue file that may still reference missing globals.
      const v = Date.now().toString();
      setVizLoading(true, "Downloading WebAssembly…");
      const mod = await import(`./pkg/bevy_mcbaise_fantasmagoria.js?v=${v}`);
      // wasm-bindgen requires explicit initialization; otherwise exports will exist but call into
      // an uninitialized internal `wasm` instance.
      setVizLoading(true, "Initializing WebAssembly…");
      await mod.default({ module_or_path: `./pkg/bevy_mcbaise_fantasmagoria_bg.wasm?v=${v}` });
      wasm = mod;
      // The app will call `mcbaise_set_wasm_ready()` from Rust when it finishes startup.
      refreshLoading();
    }

    // Rate-capped coalescer for `wasm.set_video_time`.
    // - Coalesces rapid updates and only flushes the latest time.
    // - Enforces a minimum interval (`WASM_MIN_INTERVAL_MS`) to avoid saturating
    //   the main thread when many frames or messages arrive.
    // - Uses `requestIdleCallback` when available to prefer idle time, falling
    //   back to `setTimeout`.
    let _wasmPending = null;
    let _wasmPendingTimer = null;
    let _wasmPendingIsIdle = false;
    let _wasmLastFlush = 0;
    const WASM_MIN_INTERVAL_MS = 33; // ~30Hz

    function _flushWasmPending() {
      try {
        const args = _wasmPending || { timeSec: 0, playing: false };
        _wasmPending = null;
        // clear the timer id (either idle callback id or timeout id)
        _wasmPendingTimer = null;
        _wasmPendingIsIdle = false;
        _wasmLastFlush = performance.now();
        if (typeof wasm?.set_video_time === 'function') {
          try { wasm.set_video_time(args.timeSec, !!args.playing); } catch (e) { if (window.__MCBAISE_DEBUG) console.error('mcbaise:schedule:flush:error', e); }
        }
      } catch (e) { if (window.__MCBAISE_DEBUG) console.error('mcbaise:schedule:flush:outer', e); }
    }

    function scheduleWasmSetVideoTime(timeSec, playing) {
      try {
        _wasmPending = { timeSec: Number(timeSec) || 0, playing: !!playing };
        // If a flush is already scheduled, just coalesce into _wasmPending.
        if (_wasmPendingTimer) return;

        const now = performance.now();
        const since = now - (_wasmLastFlush || 0);
        const scheduleImmediately = since >= WASM_MIN_INTERVAL_MS;

        const doSchedule = (delay) => {
          try {
            if (typeof requestIdleCallback !== 'undefined' && scheduleImmediately) {
              // Try to use idle time but cap timeout so we don't delay too long.
              try {
                _wasmPendingIsIdle = true;
                _wasmPendingTimer = requestIdleCallback(() => _flushWasmPending(), { timeout: 50 });
              } catch (_) {
                _wasmPendingIsIdle = false;
                _wasmPendingTimer = setTimeout(() => _flushWasmPending(), 0);
              }
            } else {
              // Either we are inside the min-interval window or RIC unavailable.
              _wasmPendingIsIdle = false;
              _wasmPendingTimer = setTimeout(() => _flushWasmPending(), delay);
            }
          } catch (e) { if (window.__MCBAISE_DEBUG) console.error('mcbaise:schedule:doSchedule:error', e); }
        };

        if (scheduleImmediately) {
          doSchedule(0);
        } else {
          // schedule after remaining interval to enforce rate cap
          const delay = Math.max(0, Math.ceil(WASM_MIN_INTERVAL_MS - since));
          doSchedule(delay);
        }
      } catch (e) { if (window.__MCBAISE_DEBUG) console.error('mcbaise:schedule:error', e); }
    }

    // YouTube player.
    let player = null;
    let playerReady = false;
    let isPlaying = false;

    // Bridge module-scoped player state to `window` so non-module scripts (e.g.
    // the GIF recorder <script>) and extra-viz iframes can query it safely.
    function _mcbaise_set_global_player_state() {
      try { window._mcbaise_playerReady = !!playerReady; } catch (_) {}
      try { window._mcbaise_isPlaying = !!isPlaying; } catch (_) {}
      try { window._mcbaise_player = player || null; } catch (_) {}
      try { if (typeof scheduleWasmSetVideoTime === 'function') window._mcbaise_scheduleWasmSetVideoTime = scheduleWasmSetVideoTime; } catch (_) {}
      try { if (typeof broadcastSync === 'function') window._mcbaise_broadcastSync = broadcastSync; } catch (_) {}
      try { if (typeof broadcastTime === 'function') window._mcbaise_broadcastTime = broadcastTime; } catch (_) {}
      try {
        window._mcbaise_getPlayerState = () => {
          const ready = !!playerReady;
          const t = ready ? (player?.getCurrentTime?.() ?? 0) : 0;
          const rate = (player?.getPlaybackRate?.() ?? 1);
          return { playerReady: ready, playing: !!isPlaying, timeSec: Number(t) || 0, rate: Number(rate) || 1 };
        };
      } catch (_) {}
    }
    _mcbaise_set_global_player_state();
    let rafId = null;
    let pollId = null;
    let lastBroadcastMs = 0;
    // Throttle advisory 'tick' broadcasts to avoid saturating the renderer
    // while keeping visuals reasonably smooth. Use ~100ms (≈10Hz) by default.
    // Authoritative syncs remain controlled by `SYNC_THROTTLE_MS`.
    const BROADCAST_THROTTLE_MS = 100; // ms between non-authoritative ticks (~10Hz)
    let lastSyncSentMs = 0;
    let SYNC_THROTTLE_MS = 5000; // send authoritative syncs at ~0.2Hz (visible divergence)
    let pendingPlayingRequest = null;

    // Helper: schedule DOM writes on the next animation frame cycle (double-buffer)
    function scheduleWrite(fn) {
      requestAnimationFrame(() => requestAnimationFrame(fn));
    }

    // We always prefer local interpolation on children for smooth visuals.
    // The parent will continue to send authoritative syncs at `SYNC_THROTTLE_MS`.

    // Extra viz instances are injected as iframes so they can run a separate wasm app.
    // This avoids wasm-bindgen's single-instance limitation within one document.
    // Track injected viz iframes as objects so we can retry/post-initialize reliably.
    const extraVizFrames = [];
    // Also expose on `window` so code that runs in slightly different scopes
    // (or debug helpers) can access the same array without throwing.
    try { window._mcbaise_extraVizFrames = extraVizFrames; } catch (_) {}
    // Observers and policy settings for priority/backoff
    const MAX_FULL_QUALITY = 3; // keep top N frames at full quality
    let io = null; // IntersectionObserver
    try {
      io = new IntersectionObserver((entries) => {
        for (const ent of entries) {
          const f = extraVizFrames.find(x => x.iframe === ent.target);
          if (f) {
            f._intersectionRatio = ent.intersectionRatio;
            updateFramePolicy(f);
          }
        }
        updateAllPolicies();
      }, { threshold: [0, 0.01, 0.1, 0.25, 0.5, 0.75, 1] });
    } catch (_) { io = null; }

    function sendPolicyToFrame(f, policy) {
      try {
        if (f.port && typeof f.port.postMessage === 'function') {
          f.port.postMessage({ type: 'policy', policy });
        } else {
          _postToFrame(f, { type: 'policy', policy });
        }
      } catch (e) { console.warn('mcbaise:sendPolicy failed', e); }
    }

    function computePriorityScore(f) {
      // Higher is better. Use intersection ratio and size.
      try {
        const rect = f.iframe.getBoundingClientRect();
        const area = Math.max(0, rect.width * rect.height);
        const visible = (f._intersectionRatio || 0) > 0.01;
        // Prefer larger visible frames.
        return (visible ? 1 : 0) * (f._intersectionRatio || 0) + Math.log10(Math.max(1, area));
      } catch (_) { return 0; }
    }

    function updateAllPolicies() {
      // Rank frames by priority score and assign full quality to top N.
      const ranked = Array.from(extraVizFrames).map(f => ({ f, score: computePriorityScore(f) }));
      ranked.sort((a, b) => b.score - a.score);
      for (let i = 0; i < ranked.length; i++) {
        const f = ranked[i].f;
        // If the parent requested precise mode, force full quality for all frames
        // so they render frequently and stay tightly in sync.
        const base = (i < MAX_FULL_QUALITY) ? { mode: 'high', fps: 60, scale: 1 } : (ranked[i].score > 0 ? { mode: 'medium', fps: 30, scale: 0.75 } : { mode: 'low', fps: 8, scale: 0.5 });
        // Always allow interpolation on children for smooth local playback.
        const policy = Object.assign({}, base, { interpolate: true });
        // attach policy for later checks
        f._policy = policy;
        sendPolicyToFrame(f, policy);
      }
    }

    function updateFramePolicy(f) {
      // Called when an individual frame's visibility/size changes — just re-evaluate all.
      try { updateAllPolicies(); } catch (_) {}
    }

    // Debounced resize handler to recompute policies when the viewport/layout changes.
    (function() {
      let _resizeTimer = null;
      window.addEventListener('resize', () => {
        try {
          if (_resizeTimer) clearTimeout(_resizeTimer);
          _resizeTimer = setTimeout(() => {
            try { updateAllPolicies(); } catch (_) {}
          }, 120);
        } catch (_) {}
      });
    })();

    function _postToFrame(frameLike, msg) {
      try {
        // support both raw iframe element and our { iframe, ready, port } objects
        // If a MessagePort is attached to the frame, use it (more efficient).
        if (frameLike?.port && typeof frameLike.port.postMessage === 'function') {
          frameLike.port.postMessage(msg);
          return true;
        }
        const win = frameLike?.contentWindow || frameLike?.iframe?.contentWindow;
        console.debug('mcbaise:postToFrame', { msg, hasWindow: !!win, hasPort: !!frameLike?.port, frameLike });
        if (!win) return false;
        // Try with PAGE_ORIGIN first; for blob/opaque frames fall back to '*'.
        try {
          win.postMessage(msg, PAGE_ORIGIN);
        } catch (e) {
          try { win.postMessage(msg, '*'); } catch (e2) { return false; }
        }
        return true;
      } catch (err) {
        console.warn('mcbaise:postToFrame error', err);
        return false;
      }
    }

    function broadcastTime(timeSec, playing) {
      if (window.__MCBAISE_DEBUG) console.debug('mcbaise:broadcastTime', { timeSec, playing, count: extraVizFrames.length });
      // Iterate a copy since we may prune dead frames.
      const nowMs = performance.now();
      // Use the configured authoritative throttle for syncs.
      const shouldSync = ((nowMs - lastSyncSentMs) >= SYNC_THROTTLE_MS);
      for (const f of Array.from(extraVizFrames)) {
        try {
          // Prefer to send through a MessagePort if available (lower overhead).
          if (f.port && typeof f.port.postMessage === 'function') {
            try {
              if (shouldSync) f.port.postMessage({ type: 'sync', timeSec, playing: !!playing, rate: (player?.getPlaybackRate?.() ?? 1), parent_ts_ms: Date.now() });
              else f.port.postMessage({ type: 'tick', timeSec, playing: !!playing });
              try { f._lastSeen = nowMs; } catch (_) {}
            } catch (e) { console.warn('mcbaise:port.postMessage failed', e); }
          } else {
            // fallback: only send authoritative syncs at a lower cadence via postMessage
              if (shouldSync) {
                const ok = _postToFrame(f, { type: 'sync', timeSec, playing: !!playing, rate: (player?.getPlaybackRate?.() ?? 1), parent_ts_ms: Date.now() });
                if (ok) try { f._lastSeen = nowMs; } catch (_) {}
                if (!ok) continue;
              }
          }
        } catch (e) {
          console.warn('mcbaise:broadcastTime:postMessage failed', e);
          // Remove problematic frame from list to avoid repeated failures.
          const idx = extraVizFrames.indexOf(f);
          if (idx !== -1) extraVizFrames.splice(idx, 1);
        }
      }
      if (shouldSync) lastSyncSentMs = nowMs;
    }

    function broadcastSync(timeSec, playing) {
      // Immediate authoritative sync to all frames (used on play/pause/seek)
      for (const f of Array.from(extraVizFrames)) {
        try {
          if (f.port && typeof f.port.postMessage === 'function') {
            try { f.port.postMessage({ type: 'sync', timeSec, playing: !!playing, rate: (player?.getPlaybackRate?.() ?? 1), parent_ts_ms: Date.now() }); } catch (e) { console.warn('mcbaise:port.postMessage failed', e); }
          } else {
            try { _postToFrame(f, { type: 'sync', timeSec, playing: !!playing, rate: (player?.getPlaybackRate?.() ?? 1), parent_ts_ms: Date.now() }); } catch (_) {}
          }
        } catch (_) {}
      }
      lastSyncSentMs = performance.now();
    }

    // Health-check: if any frame hasn't been seen by parent traffic for a while,
    // try to nudge it by sending a targeted authoritative sync. This helps
    // recover dynamically-added frames that failed to receive messages or
    // whose event loop stalled.
    try {
      setInterval(() => {
        try {
          if (!isPlaying) return;
          const now = Date.now();
          for (const f of Array.from(extraVizFrames)) {
            try {
              const last = Number(f._lastSeen || 0);
              if ((now - last) > 8000) {
                // nudge this frame
                const t = playerReady ? (player?.getCurrentTime?.() ?? 0) : 0;
                try {
                  if (f.port && typeof f.port.postMessage === 'function') {
                    f.port.postMessage({ type: 'sync', timeSec: t, playing: !!isPlaying, rate: (player?.getPlaybackRate?.() ?? 1), parent_ts_ms: Date.now() });
                  } else {
                    _postToFrame(f, { type: 'sync', timeSec: t, playing: !!isPlaying, rate: (player?.getPlaybackRate?.() ?? 1), parent_ts_ms: Date.now() });
                  }
                } catch (_) {}
                try { f._lastSeen = Date.now(); } catch (_) {}
              }
            } catch (_) {}
          }
        } catch (_) {}
      }, 3000);
    } catch (_) {}

    // Send a short burst of authoritative syncs spaced a few ms apart to
    // reduce visible snapping when toggling precise mode on.
    function burstSync(count = 3, spacingMs = 16) {
      for (let i = 0; i < count; i++) {
        setTimeout(() => {
          try {
            const t = (player && typeof player.getCurrentTime === 'function') ? player.getCurrentTime() : 0;
            broadcastSync(t, !!isPlaying);
          } catch (_) {}
        }, i * spacingMs);
      }
    }

    function broadcastVisibility(show) {
      console.debug('mcbaise:broadcastVisibility', { show, count: extraVizFrames.length });
      for (const f of extraVizFrames) {
        _postToFrame(f, { type: 'mcbaise_set_video_visible', show: !!show });
      }
      // Also inform wasm in this page (if it exposes a handler).
      try {
        wasm?.set_video_visible?.(!!show);
      } catch (_) {}
    }

    // Set video visibility intelligently: if there are additional viz panes
    // inserted above/below the player we hide only the player contents; if
    // there are no extra viz panes we collapse the entire left column.
    function setVideoVisibility(show) {
      if (!rootEl) return;
      const leftCol = document.getElementById('left');
      const extras = leftCol ? leftCol.querySelectorAll('.extraViz') : [];
      const hasExtras = extras && extras.length > 0;

      if (show) {
        if (playerWrapEl) playerWrapEl.classList.remove('hidePlayer');
        rootEl.classList.remove('hideVideo');
      } else {
        if (hasExtras) {
          // Preserve the left column (it contains extra viz panes); hide only the player area.
          if (playerWrapEl) playerWrapEl.classList.add('hidePlayer');
          rootEl.classList.remove('hideVideo');
        } else {
          // No extras — fully collapse the left column.
          rootEl.classList.add('hideVideo');
          if (playerWrapEl) playerWrapEl.classList.remove('hidePlayer');
        }
      }

      try { broadcastVisibility(show); } catch (_) {}
    }

    // Apply visibility locally in this document (used by viz-only iframes
    // when they receive a broadcast from the parent). This updates the DOM
    // and notifies the local wasm instance if available.
    function applyLocalVideoVisibility(show) {
      try {
        if (playerWrapEl) {
          if (show) playerWrapEl.classList.remove('hidePlayer');
          else playerWrapEl.classList.add('hidePlayer');
        }
      } catch (_) {}
      try { wasm?.set_video_visible?.(!!show); } catch (_) {}
    }

    // Receive play/pause/visibility requests from child viz iframes.
    // Accept both legacy `{ mcbaise_request_playing: 'play' }` shapes and
    // the `{ type: 'mcbaise_request_playing', playing: true }` message style used by viz-only frames.
    window.addEventListener('message', (ev) => {
      console.debug('mcbaise:parent:message', { origin: ev.origin, data: ev.data });
      const d = ev.data || {};
      if (!d || typeof d !== 'object') return;

      // Child watchdog may ask for an immediate authoritative sync.
      if (d.type === 'child_watchdog_request_sync') {
        try {
          const src = ev.source;
          const f = extraVizFrames.find(x => (x.iframe && x.iframe.contentWindow) === src);
          const t = playerReady ? (player?.getCurrentTime?.() ?? 0) : 0;
          if (f) {
            try {
              if (f.port && typeof f.port.postMessage === 'function') f.port.postMessage({ type: 'sync', timeSec: t, playing: !!isPlaying, rate: (player?.getPlaybackRate?.() ?? 1) });
              else _postToFrame(f, { type: 'sync', timeSec: t, playing: !!isPlaying, rate: (player?.getPlaybackRate?.() ?? 1) });
            } catch (_) {}
          } else {
            // fallback: broadcast sync to all
            broadcastSync(t, !!isPlaying);
          }
        } catch (_) {}
        return;
      }

      // Ignore child time pushes — parent is authoritative for time.
      if (d.mcbaise_time !== undefined || d.type === 'mcbaise_time') return;

      // Play/pause: support both shapes
      if (d.type === 'mcbaise_request_playing') {
        if (d.playing) player?.playVideo?.();
        else player?.pauseVideo?.();
      } else if (d.mcbaise_request_playing) {
        if (d.mcbaise_request_playing === 'play') player?.playVideo?.();
        if (d.mcbaise_request_playing === 'pause') player?.pauseVideo?.();
      }

      // Visibility: support both `{ type: 'mcbaise_set_video_visible', show }` and `{ mcbaise_set_video_visible: true }`.
      if (d.type === 'mcbaise_set_video_visible' || d.mcbaise_set_video_visible !== undefined) {
        const visible = d.type === 'mcbaise_set_video_visible' ? !!d.show : !!d.mcbaise_set_video_visible;
        setVideoVisibility(visible);
        return;
      }

      if (d.type === 'mcbaise_set_video_visible_ack') {
        console.debug('mcbaise: child acked visibility change', { applied: d.applied });
        return;
      }
    });

    // Called from Rust (wasm) to request play/pause.
    // Note: may be called before the YouTube player is ready.
    globalThis.mcbaise_request_playing = (playing) => {
      if (vizOnly) {
        // In a viz-only iframe: ask the parent to control the video.
        try {
          window.parent?.postMessage({ type: "mcbaise_request_playing", playing: !!playing }, PAGE_ORIGIN);
        } catch (_) {}
        return;
      }

      const want = !!playing;
      pendingPlayingRequest = want;

      if (!playerReady || !player) return;
      try {
        if (want) player.playVideo?.();
        else player.pauseVideo?.();
      } catch (e) {
        console.warn('mcbaise_request_playing failed', e);
      }
    };

    function startLoop() {
      if (rafId) return;
      const loop = () => {
        rafId = requestAnimationFrame(loop);
        try {
          const t0 = performance.now();
          if (!playerReady || !player?.getCurrentTime) return;
          const nowMs = performance.now();
          if (nowMs - lastBroadcastMs < BROADCAST_THROTTLE_MS) return;
          lastBroadcastMs = nowMs;
          const t = player.getCurrentTime();

          // Time sub-steps so we can tell whether wasm.set_video_time or
          // broadcastTime/postMessage is responsible for long rAFs.
          const stepStart = performance.now();
          let afterSetVideo = stepStart;
          if (typeof wasm?.set_video_time === 'function') {
            // Schedule the wasm call asynchronously to avoid blocking the rAF.
            try { scheduleWasmSetVideoTime(t, !!isPlaying); } catch (e) { if (window.__MCBAISE_DEBUG) console.error('mcbaise:parent:schedule:error', e); }
            afterSetVideo = performance.now();
          } else {
            // no wasm yet; mark afterSetVideo equal to start so durations reflect only broadcast
            afterSetVideo = performance.now();
          }

          const beforeBroadcast = performance.now();
          try { broadcastTime(t, !!isPlaying); } catch (e) { if (window.__MCBAISE_DEBUG) console.error('mcbaise:parent:broadcastTime:error', e); }
          const afterBroadcast = performance.now();

          const dur_set = Math.round((afterSetVideo - stepStart));
          const dur_broadcast = Math.round((afterBroadcast - beforeBroadcast));
          const total = Math.round(afterBroadcast - t0);
          if (window.__MCBAISE_DEBUG && total > 50) console.warn('mcbaise:parent:rAF:work', { total: total + 'ms', set_video_time_ms: dur_set + 'ms', broadcast_ms: dur_broadcast + 'ms' });
        } catch (e) {
          if (window.__MCBAISE_DEBUG) console.error('mcbaise:parent:rAF:error', e);
        }
      };
      loop();
    }

    function stopLoop() {
      if (rafId) cancelAnimationFrame(rafId);
      rafId = null;
    }

    function startPoll() {
      if (pollId) return;
      pollId = setInterval(() => {
        if (!playerReady || !player?.getCurrentTime) return;
        const t = player.getCurrentTime();
        // Use the scheduler to avoid synchronous wasm blocking inside the interval tick.
          try { scheduleWasmSetVideoTime(t, !!isPlaying); } catch (e) { if (window.__MCBAISE_DEBUG) console.error('mcbaise:poll:schedule:error', e); }
          broadcastTime(t, !!isPlaying);
        }, 100);
    }

    function stopPoll() {
      if (pollId) clearInterval(pollId);
      pollId = null;
    }

    window.onYouTubeIframeAPIReady = () => {
      ytReady = false;
      setYoutubeLoading(true, "Preparing the player…");
      refreshLoading();
      player = new YT.Player("player", {
        videoId: VIDEO_ID,
        width: "100%",
        height: "100%",
        playerVars: {
          autoplay: 0,
          controls: 1,
          rel: 0,
          modestbranding: 1,
          playsinline: 1,
          enablejsapi: 1,
          // Required on some browsers/devices to avoid postMessage origin mismatch.
          origin: PAGE_ORIGIN,
        },
        events: {
          onReady: () => {
            playerReady = true;
            ytReady = true;
            _mcbaise_set_global_player_state();
            setYoutubeLoading(false, "");
            refreshLoading();
            const t = player.getCurrentTime?.() ?? 0;
            wasm?.set_video_time?.(t, false);
            try { broadcastSync(t, false); } catch (_) { broadcastTime(t, false); }

            if (pendingPlayingRequest !== null) {
              try {
                if (pendingPlayingRequest) player.playVideo?.();
                else player.pauseVideo?.();
              } catch (e) {
                console.warn('mcbaise_request_playing (deferred) failed', e);
              }
            }
          },
          onStateChange: (e) => {
            if (e.data === YT.PlayerState.PLAYING) {
              isPlaying = true;
              _mcbaise_set_global_player_state();
              startLoop();
              startPoll();
                // immediate authoritative sync when playback starts
                try { const t = playerReady ? (player.getCurrentTime?.() ?? 0) : 0; broadcastSync(t, true); } catch (_) {}
            } else {
              isPlaying = false;
              _mcbaise_set_global_player_state();
              const t = playerReady ? (player.getCurrentTime?.() ?? 0) : 0;
              wasm?.set_video_time?.(t, false);
                // authoritative sync on pause/stop
                try { broadcastSync(t, false); } catch (_) {}
              stopLoop();
              stopPoll();
            }
          },
          onPlaybackRateChange: () => {
            // Keep wasm time/playing fresh when playback rate changes.
            const t = playerReady ? (player.getCurrentTime?.() ?? 0) : 0;
            wasm?.set_video_time?.(t, !!isPlaying);
              _mcbaise_set_global_player_state();
              try { broadcastSync(t, !!isPlaying); } catch (_) {}
          },
          onError: (err) => {
            console.warn('YouTube player error', err);
            const t = playerReady ? (player.getCurrentTime?.() ?? 0) : 0;
            wasm?.set_video_time?.(t, false);
              _mcbaise_set_global_player_state();
              try { broadcastSync(t, false); } catch (_) {}
            stopLoop();
            stopPoll();
          }
        }
      });
    };

    // Parent responder: allow same-origin extra-viz iframes to ask if the player is ready.
    try {
      if (!window._mcbaise_player_state_responder_installed) {
        window._mcbaise_player_state_responder_installed = true;
        window.addEventListener('message', (ev) => {
          try {
            const d = ev && ev.data;
            if (!d || typeof d !== 'object') return;
            if (d.type !== 'request_player_state') return;
            // same-origin only
            if (typeof PAGE_ORIGIN === 'string' && PAGE_ORIGIN && ev.origin && ev.origin !== 'null' && ev.origin !== PAGE_ORIGIN) return;
            const state = (typeof window._mcbaise_getPlayerState === 'function')
              ? window._mcbaise_getPlayerState()
              : { playerReady: false, playing: false, timeSec: 0, rate: 1 };
            const reply = { type: 'player_state', ...state };
            try { ev.source?.postMessage?.(reply, PAGE_ORIGIN || '*'); } catch (_) { try { ev.source?.postMessage?.(reply, '*'); } catch (_) {} }
          } catch (_) {}
        });
      }
    } catch (_) {}

    // In viz-only mode, receive time/visibility/playback updates from the parent page.
    // Support both window.postMessage and an attached MessagePort (preferred).
    (function() {
      let childPort = null;
      let childLoopId = null;
      let lastSync = { timeSec: 0, tsMs: 0, playing: false, rate: 1 };
      // childPolicy controls local throttling and smoothing behavior. Default
      // includes `interpolate: true` so children smooth between authoritative
      // sync samples by default.
      let childPolicy = { mode: 'high', fps: 60, scale: 1, interpolate: true };
      let _lastAppliedMs = 0;

      function applyPolicy(policy) {
        try {
          childPolicy = Object.assign({}, childPolicy, policy || {});
          // If wasm exposes a render scale API, call it; otherwise we prefer to only throttle time updates.
          try {
            console.debug('mcbaise:child:applyPolicy', childPolicy);
            // Prefer calling the wasm export `set_render_scale(scale)` if available.
            // In many cases the wasm module may not yet be initialized when the
            // first policy arrives; attempt a few short retries rather than
            // failing silently so devs can toggle scale from the parent early.
            function ensureRenderScale(scale, attemptsLeft = 6) {
              try {
                if (typeof wasm?.set_render_scale === 'function') {
                  try { wasm.set_render_scale(scale); return true; } catch (e) { if (window.__MCBAISE_DEBUG) console.warn('mcbaise:child:set_render_scale:call_failed', e); }
                }
              } catch (_) {}
              if (attemptsLeft <= 0) {
                if (window.__MCBAISE_DEBUG) console.debug('mcbaise:child:applyPolicy - no wasm.set_render_scale after retries, skipping JS canvas resize');
                return false;
              }
              // Retry after a short delay — keeps retry lightweight and bounded.
              setTimeout(() => ensureRenderScale(scale, attemptsLeft - 1), 200);
              return false;
            }
            ensureRenderScale(childPolicy.scale);
          } catch (_) {}
        } catch (_) {}
      }

      // Recompute canvas/application sizing when the viewport or canvas element resizes.
      try {
        let _childResizeTimer = null;
        window.addEventListener('resize', () => {
          try {
            if (_childResizeTimer) clearTimeout(_childResizeTimer);
            _childResizeTimer = setTimeout(() => {
              try { applyPolicy(childPolicy); } catch (_) {}
            }, 120);
          } catch (_) {}
        });

        // Also observe the canvas element for size changes so we can reapply or restore scale.
        try {
          const c = document.getElementById('bevy-canvas');
          if (c && typeof ResizeObserver !== 'undefined') {
            const ro = new ResizeObserver(() => {
              try {
                if (_childResizeTimer) clearTimeout(_childResizeTimer);
                _childResizeTimer = setTimeout(() => { try { applyPolicy(childPolicy); } catch (_) {} }, 80);
              } catch (_) {}
            });
            try { ro.observe(c); } catch (_) {}
          }
        } catch (_) {}
      } catch (_) {}

      // Correction state used to smoothly converge to authoritative time
      // without visible jumps. `correctionVel` is seconds-per-second to add
      // to the nominal playback rate for a short convergence window.
      let _correctionVel = 0;
      let _correctionUntil = 0;

      function startChildLoop() {
        if (childLoopId) return;
        const step = () => {
            childLoopId = requestAnimationFrame(step);
            try {
              const t0 = performance.now();
              const now = performance.now();
              let t = Number(lastSync.timeSec) || 0;
            // If interpolation is enabled, locally integrate time forward from
            // the last authoritative sync. If disabled, remain perfectly
            // authoritative by using the last sync time directly.
            if (childPolicy.interpolate && lastSync.playing) {
              const dt = (now - (lastSync.tsMs || now)) / 1000;
              // If we have an active correction velocity, blend it in and
              // reduce it over time until the correction window expires.
              let vel = Number(lastSync.rate || 1);
              if (_correctionUntil > now) {
                vel += _correctionVel;
              }
              t = t + dt * vel;
            } else {
              // stay exactly at authoritative time (no local extrapolation)
              t = Number(lastSync.timeSec) || 0;
            }
            // Throttle actual wasm updates according to policy.fps
            const minInterval = 1000 / (childPolicy.fps || 60);
            if ((now - _lastAppliedMs) >= minInterval) {
              const subStart = performance.now();
              let afterSet = subStart;
                if (typeof wasm?.set_video_time === 'function') {
                  try { scheduleWasmSetVideoTime(t, !!lastSync.playing); } catch (e) { if (window.__MCBAISE_DEBUG) console.error('mcbaise:child:schedule:error', e); }
                  afterSet = performance.now();
                } else {
                  afterSet = performance.now();
                }
              _lastAppliedMs = now;
              const dur_total = Math.round(performance.now() - t0);
              const dur_set = Math.round(afterSet - subStart);
              if (window.__MCBAISE_DEBUG && dur_total > 50) console.warn('mcbaise:child:rAF:work', { total: dur_total + 'ms', set_video_time_ms: dur_set + 'ms' });
            }
          } catch (_) {}
        };
        step();
      }

      function stopChildLoop() {
        if (!childLoopId) return;
        cancelAnimationFrame(childLoopId);
        childLoopId = null;
      }

      // child-side clock offset (ms) applied to parent timestamps: parent_ts + offset -> child clock
      let childClockOffsetMs = 0;

      function applySync(timeSec, playing, rate, parent_ts_ms) {
        // Authoritative sync from parent. We implement latency compensation
        // and a smooth phase-correction to reduce visible jumps while being
        // more accurate than naive interpolation.
        const nowPerf = performance.now();
        const nowWall = Date.now();

        // Predict current local playback time based on previous authoritative
        // sample (if any) and local integration.
        let predictedLocal = Number(lastSync.timeSec || 0);
        if (childPolicy.interpolate && lastSync.playing) {
          const prevTs = Number(lastSync.tsMs || nowPerf);
          const dt = (nowPerf - prevTs) / 1000;
          predictedLocal = predictedLocal + dt * (Number(lastSync.rate || 1) + (_correctionUntil > nowPerf ? _correctionVel : 0));
        }

        // Estimate one-way transport delay using parent_ts_ms corrected by any measured clock offset.
        let transportMs = 0;
        try {
          const parentTs = Number(parent_ts_ms || nowWall);
          const adjustedParentWall = parentTs + (childClockOffsetMs || 0);
          transportMs = Math.max(0, nowWall - adjustedParentWall);
        } catch (_) { transportMs = 0; }

        // Compute adjusted authoritative time by accounting for transport delay.
        const adjustedAuthoritative = Number(timeSec || 0) + (transportMs / 1000) * (Number(rate || 1));

        // Error between authoritative and our predicted local time.
        const err = adjustedAuthoritative - predictedLocal;

        // Decide snap vs. smooth correction. If error is large, snap immediately.
        const SNAP_THRESHOLD = 0.25; // seconds
        const CONVERGENCE_MS = 300; // convergence window for phase correction (ms)

        lastSync.timeSec = Number(timeSec) || 0;
        lastSync.tsMs = nowPerf;
        lastSync.playing = !!playing;
        lastSync.rate = Number(rate) || 1;

          if (Math.abs(err) > SNAP_THRESHOLD) {
          // Large error — snap to adjusted authoritative time to avoid long drift.
          try { requestAnimationFrame(() => { try { wasm?.set_video_time?.(adjustedAuthoritative, lastSync.playing); } catch (_) {} }); } catch (_) {}
          // clear any small corrections
          _correctionVel = 0;
          _correctionUntil = 0;
        } else {
          // Small error — apply temporary correction velocity to converge smoothly.
          // We compute a velocity (seconds/sec) that will remove `err` over CONVERGENCE_MS.
          const convergenceSec = Math.max(0.05, CONVERGENCE_MS / 1000);
          _correctionVel = err / convergenceSec; // this will be added to playback rate
          // clamp correction to reasonable bounds to avoid crazy speeds
          const MAX_CORRECTION = 1.0; // allow up to +1s/s additional speed
          if (_correctionVel > MAX_CORRECTION) _correctionVel = MAX_CORRECTION;
          if (_correctionVel < -MAX_CORRECTION) _correctionVel = -MAX_CORRECTION;
          _correctionUntil = nowPerf + CONVERGENCE_MS;
          // Apply an immediate small adjust to be responsive (but not a snap)
          try { requestAnimationFrame(() => { try { wasm?.set_video_time?.(predictedLocal, lastSync.playing); } catch (_) {} }); } catch (_) {}
        }

        if (lastSync.playing) startChildLoop(); else stopChildLoop();
      }

      function handleChildMessage(data, origin) {
        if (!data || typeof data !== 'object') return;
        if (data.type === 'player_state') {
          // Initial parent state query response.
          applySync(data.timeSec, data.playing, data.rate, Date.now());
          return;
        }
        // Accept both legacy and new message shapes. Treat both as authoritative sync.
        if (data.type === 'sync' || data.type === 'mcbaise_time') {
          applySync(data.timeSec, data.playing, data.rate, data.parent_ts_ms);
          return;
        }
        if (data.type === 'policy') {
          try { applyPolicy(data.policy); } catch (_) {}
          return;
        }
        // Respond to ping messages from the parent for clock/Round-Trip Time estimation.
        if (data.type === 'ping') {
          try {
            const t_child_recv_ms = Date.now();
            // Reply on the same port to the parent with the timestamp we received it.
            try { childPort.postMessage({ type: 'pong', id: data.id, t_parent_send_ms: data.t_parent_send_ms, t_child_recv_ms }); } catch (_) {}
          } catch (_) {}
          return;
        }
        // Parent may send a computed clock offset to the child to apply.
        if (data.type === 'clock_offset') {
          try { childClockOffsetMs = Number(data.offset_ms) || 0; } catch (_) { childClockOffsetMs = 0; }
          console.debug('mcbaise:child:clock_offset', childClockOffsetMs);
          return;
        }
        // Lightweight 'tick' messages are advisory; ignore for now to avoid thrash.
        if (data.type === 'tick') {
          return;
        }
        if (data.type === 'mcbaise_set_video_visible') {
          try { applyLocalVideoVisibility?.(!!data.show); } catch (_) {}
          try { window.parent?.postMessage({ type: 'mcbaise_set_video_visible_ack', applied: !!data.show }, PAGE_ORIGIN); } catch (_) {}
          return;
        }
        // Parent may request a snapshot of the local canvas for recording.
        if (data.type === 'request_snapshot') {
          (async () => {
            try {
              const reqSyncId = (data && (data.syncId != null)) ? String(data.syncId) : null;
              const reqTimeSec = (data && (data.timeSec != null)) ? Number(data.timeSec) : null;
              const reqPlaying = !!(data && data.playing);

              const c = document.getElementById('bevy-canvas') || document.querySelector('canvas');
              if (!c || !(c instanceof HTMLCanvasElement)) {
                // Reply explicitly with null to indicate failure.
                try { childPort?.postMessage?.({ type: 'snapshot', dataUrl: null, syncId: reqSyncId, timeSec: reqTimeSec }); } catch (_) { window.parent.postMessage({ type: 'snapshot', dataUrl: null, syncId: reqSyncId, timeSec: reqTimeSec }, PAGE_ORIGIN); }
                return;
              }

              // If the parent provided a target time, force this wasm instance to that time
              // before capturing to keep all panes in sync.
              try {
                if (reqTimeSec != null && Number.isFinite(reqTimeSec)) {
                  // Prefer scheduling so we don't block message handler.
                  if (typeof scheduleWasmSetVideoTime === 'function') {
                    try { scheduleWasmSetVideoTime(reqTimeSec, reqPlaying); } catch (_) {}
                  } else {
                    try { wasm?.set_video_time?.(reqTimeSec, reqPlaying); } catch (_) {}
                  }
                }
              } catch (_) {}

              // Wait a couple frames so rendering catches up before capturing.
              try {
                await new Promise((res) => requestAnimationFrame(() => requestAnimationFrame(res)));
              } catch (_) {}

              // Preferred snapshot path: trigger the wasm GPU readback pipeline.
              // This avoids WebGPU canvas readback / toDataURL blank frames.
              // The wasm side will postMessage({type:'wasm_pixels', pixels:ArrayBuffer, width, height, gpu:true, ...}) to the parent.
              try {
                if (wasmReady && typeof wasm?.request_wasm_readback_gpu === 'function') {
                  try { wasm.request_wasm_readback_gpu(); } catch (_) {}

                  // Tell the parent we did trigger readback (helps separate "never requested" from "requested but never delivered").
                  try {
                    const msg = { type: 'snapshot_gpu_triggered', syncId: reqSyncId, timeSec: reqTimeSec, playing: reqPlaying, wasmReady: !!wasmReady };
                    try { childPort?.postMessage?.(msg); } catch (_) { window.parent?.postMessage?.(msg, PAGE_ORIGIN); }
                  } catch (_) {}

                  // Safety net: if the GPU mapping callback stalls (some UAs/drivers), also request the
                  // CPU pixel fallback which posts `wasm_pixels` too (gpu:false).
                  try {
                    if (typeof wasm?.request_wasm_readback_pixels === 'function') {
                      setTimeout(() => {
                        try { wasm.request_wasm_readback_pixels().catch?.(() => {}); } catch (_) {}
                      }, 150);
                    }
                  } catch (_) {}

                  // Don't send a `snapshot` reply here; the parent resolves the request
                  // when it receives the subsequent `wasm_pixels` message from this iframe.
                  return;
                }
              } catch (_) {}

              // Prefer compositor frames when available (more reliable than WebGPU readback).
              try {
                if (typeof c.captureStream === 'function' && typeof window.ImageCapture === 'function') {
                  const stream = c.captureStream(30);
                  const track = (stream && stream.getVideoTracks && stream.getVideoTracks()[0]);
                  if (track) {
                    try {
                      const ic = new ImageCapture(track);
                      const frameBitmap = await ic.grabFrame();
                      try {
                        const oc = document.createElement('canvas');
                        oc.width = frameBitmap.width;
                        oc.height = frameBitmap.height;
                        const octx = oc.getContext('2d', { willReadFrequently: true });
                        octx.drawImage(frameBitmap, 0, 0);
                        const d0 = oc.toDataURL('image/png');
                        try { frameBitmap.close?.(); } catch (_) {}
                        try { track.stop(); } catch (_) {}
                        try { childPort?.postMessage?.({ type: 'snapshot', dataUrl: d0, syncId: reqSyncId, timeSec: reqTimeSec }); } catch (_) { window.parent.postMessage({ type: 'snapshot', dataUrl: d0, syncId: reqSyncId, timeSec: reqTimeSec }, PAGE_ORIGIN); }
                        return;
                      } catch (_) {
                        try { frameBitmap.close?.(); } catch (_) {}
                        try { track.stop(); } catch (_) {}
                      }
                    } catch (_) {
                      try { track.stop(); } catch (_) {}
                    }
                  }
                }
              } catch (_) {}

              // Try toDataURL first
              try {
                const d = c.toDataURL('image/png');
                try { childPort?.postMessage?.({ type: 'snapshot', dataUrl: d, syncId: reqSyncId, timeSec: reqTimeSec }); } catch (_) { window.parent.postMessage({ type: 'snapshot', dataUrl: d, syncId: reqSyncId, timeSec: reqTimeSec }, PAGE_ORIGIN); }
                return;
              } catch (_) {}
              // Fallback: draw to an offscreen canvas after createImageBitmap
              try {
                if (typeof createImageBitmap === 'function') {
                  const bm = await createImageBitmap(c);
                  const oc = document.createElement('canvas');
                  oc.width = bm.width; oc.height = bm.height;
                  const octx = oc.getContext('2d', { willReadFrequently: true });
                  octx.drawImage(bm, 0, 0);
                  try { bm.close?.(); } catch (_) {}
                  const d2 = oc.toDataURL('image/png');
                  try { childPort?.postMessage?.({ type: 'snapshot', dataUrl: d2, syncId: reqSyncId, timeSec: reqTimeSec }); } catch (_) { window.parent.postMessage({ type: 'snapshot', dataUrl: d2, syncId: reqSyncId, timeSec: reqTimeSec }, PAGE_ORIGIN); }
                  return;
                }
              } catch (e) {
                console.debug('child snapshot fallback failed', e);
              }
              try { childPort?.postMessage?.({ type: 'snapshot', dataUrl: null, syncId: reqSyncId, timeSec: reqTimeSec }); } catch (_) { window.parent.postMessage({ type: 'snapshot', dataUrl: null, syncId: reqSyncId, timeSec: reqTimeSec }, PAGE_ORIGIN); }
            } catch (_) {
              try { childPort?.postMessage?.({ type: 'snapshot', dataUrl: null, syncId: (data && data.syncId != null) ? String(data.syncId) : null, timeSec: (data && data.timeSec != null) ? Number(data.timeSec) : null }); } catch (_) { window.parent.postMessage({ type: 'snapshot', dataUrl: null, syncId: (data && data.syncId != null) ? String(data.syncId) : null, timeSec: (data && data.timeSec != null) ? Number(data.timeSec) : null }, PAGE_ORIGIN); }
            }
          })();
          return;
        }
        if (data.type === 'mcbaise_request_playing') {
          try {
            if (data.playing) wasm?.request_playing?.(true);
            else wasm?.request_playing?.(false);
          } catch (_) {}
          return;
        }
      }

      // In viz-only mode, ask parent for initial player readiness/time.
      try {
        if (isVizOnly) {
          setTimeout(() => {
            try { window.parent?.postMessage?.({ type: 'request_player_state' }, PAGE_ORIGIN); } catch (_) { try { window.parent?.postMessage?.({ type: 'request_player_state' }, '*'); } catch (_) {} }
          }, 0);
        }
      } catch (_) {}

      window.addEventListener('message', (e) => {
        // Special-case: attach a transferred MessagePort regardless of origin.
        if (e.data && e.data.type === 'attachPort' && e.ports && e.ports[0]) {
          childPort = e.ports[0];
          try {
            childPort.onmessage = (ev) => handleChildMessage(ev.data);
            childPort.start?.();
          } catch (_) {}
          return;
        }

        // For other messages, perform origin check as before.
        if (e.origin !== PAGE_ORIGIN) {
          console.debug('mcbaise:child:ignored-origin', { origin: e.origin, expected: PAGE_ORIGIN, data: e.data });
          return;
        }
        console.debug('mcbaise:child:message', e.data);
        handleChildMessage(e.data, e.origin);
      });

      // Watchdog: if the child is supposed to be playing but the rAF loop isn't active,
      // try to (re)start it occasionally — this helps recover from cases where the
      // loop was paused by the UA and didn't resume.
      try {
        setInterval(() => {
          try {
            const now = performance.now();
            const age = now - (lastSync.tsMs || 0);
            if (lastSync.playing) {
              if (!childLoopId) {
                // If we've not received an authoritative sync for a while, nudge the parent.
                if (age > 5000) {
                  try {
                    // Prefer MessagePort if attached, otherwise fallback to window.postMessage
                    if (childPort && typeof childPort.postMessage === 'function') {
                      try { childPort.postMessage({ type: 'child_watchdog_request_sync' }); } catch (_) {}
                    } else {
                      try { window.parent?.postMessage({ type: 'child_watchdog_request_sync' }, PAGE_ORIGIN); } catch (_) {}
                    }
                  } catch (_) {}
                }
                startChildLoop();
              }
            } else {
              // if not playing, ensure loop is stopped
              if (childLoopId) stopChildLoop();
            }
          } catch (_) {}
        }, 1000);
      } catch (_) {}
    })();

    function injectExtraViz(direction) {
      if (vizOnly) return;
      direction = direction || 'right';
      // Keep it simple: only inject one extra viz per click.
      const pane = document.createElement('div');
      pane.className = 'extraViz';

      const iframe = document.createElement('iframe');
      iframe.loading = 'lazy';
      iframe.title = 'mcbaise viz';
      const u = new URL(window.location.href);
      u.searchParams.set('vizOnly', '1');
      iframe.src = u.toString();
      pane.appendChild(iframe);

      const left = document.getElementById('left');
      const playerWrap = document.getElementById('playerWrap');
      const right = document.getElementById('right');

      const isPortrait = window.matchMedia('(max-aspect-ratio: 1/1)').matches;
      if (isPortrait && (direction === 'left' || direction === 'right')) {
        // Place pane into persistent side slot so cardinal placement is preserved.
        const leftSlot = document.getElementById('sideLeftSlot');
        const rightSlot = document.getElementById('sideRightSlot');
        const slot = direction === 'left' ? leftSlot : rightSlot;
        if (slot) {
          pane.dataset.placedIn = 'sideSlot';
          pane.dataset.side = direction;
          slot.appendChild(pane);
          // Defer class additions to avoid layout thrash.
          try {
            scheduleWrite(() => {
              slot.classList.add('hasPane');
              try { rootEl.classList.add('hasPortraitExtras'); } catch (_) {}
              try { void slot.offsetHeight; } catch (_) {}
            });
          } catch (_) {
            slot.classList.add('hasPane');
            try { rootEl.classList.add('hasPortraitExtras'); } catch (_) {}
          }
        } else {
          // fallback to DOM insertion
          if (direction === 'left' && left) rootEl.insertBefore(pane, left);
          else if (direction === 'right' && right) rootEl.insertBefore(pane, right);
          else (right || left || rootEl).appendChild(pane);
          try { rootEl.classList.add('hasPortraitExtras'); } catch (_) {}
        }
      } else {
        // Deterministic placement by direction (desktop / landscape behavior)
        if (direction === 'left' && left) {
          rootEl.insertBefore(pane, left);
        } else if (direction === 'right' && right) {
          rootEl.insertBefore(pane, right);
        } else if ((direction === 'top' || direction === 'above') && left && playerWrap) {
          left.insertBefore(pane, playerWrap);
          if (isPortrait) { try { rootEl.classList.add('hasPortraitExtras'); } catch (_) {} }
        } else if ((direction === 'bottom' || direction === 'below') && left && playerWrap) {
          left.appendChild(pane);
          if (isPortrait) { try { rootEl.classList.add('hasPortraitExtras'); } catch (_) {} }
        } else {
          // fallback: append to right
          (right || left || rootEl).appendChild(pane);
          if (isPortrait) { try { rootEl.classList.add('hasPortraitExtras'); } catch (_) {} }
        }
      }

      // Track frame with readiness flag and send initial messages on load.
        const frameObj = { iframe, ready: false, port: null };
        // Create a MessageChannel for this frame; we'll transfer port2 to child on load.
        try {
          const mc = new MessageChannel();
          frameObj._localPort = mc.port1; // parent-side port
          frameObj._transferPort = mc.port2; // to be transferred to child
        } catch (_) {
          frameObj._localPort = null;
          frameObj._transferPort = null;
        }
        extraVizFrames.push(frameObj);
        // Start observing this iframe for visibility/size-based priority decisions.
        try { if (io && iframe) io.observe(iframe); } catch (_) {}
        try { updateAllPolicies(); } catch (_) {}
        // Ensure the main RAF loop is running if the player is playing.
        try { if (isPlaying) startLoop(); } catch (_) {}
        iframe.addEventListener('load', () => {
          frameObj.ready = true;
          // Transfer MessagePort to child if available
          try {
            if (frameObj._transferPort && iframe.contentWindow) {
              try {
                iframe.contentWindow.postMessage({ type: 'attachPort' }, PAGE_ORIGIN, [frameObj._transferPort]);
              } catch (e) {
                try { iframe.contentWindow.postMessage({ type: 'attachPort' }, '*', [frameObj._transferPort]); } catch (_) {}
              }
              // start listening on parent-side port
              try {
                    frameObj._localPort.start?.();
                    frameObj.port = frameObj._localPort;
                    // Set up a simple ping/pong handshake to measure RTT and clock offset
                    // so the child can correct for transport latency and any clock skew.
                    frameObj.port.onmessage = (ev) => {
                      try {
                        const d = ev.data || {};
                        if (d.type === 'pong' && typeof d.t_parent_send_ms !== 'undefined') {
                          // Compute RTT and clock offset estimate (child_time - parent_time_at_midpoint)
                          const rtt = Date.now() - Number(d.t_parent_send_ms || Date.now());
                          const offset = Number(d.t_child_recv_ms || 0) - (Number(d.t_parent_send_ms || 0) + rtt / 2);
                          frameObj._clockOffsetMs = offset;
                          // Send the computed offset to the child so it can correct locally.
                          try { frameObj.port.postMessage({ type: 'clock_offset', offset_ms: offset }); } catch (_) {}
                          console.debug('mcbaise:ping', { rtt, offset, frame: frameObj });
                        } else if (d && d.type === 'snapshot_ready') {
                          frameObj._snapshotReady = true;
                          console.debug('mcbaise:port:snapshot_ready', { frame: frameObj });
                        } else if (d && d.type === 'snapshot') {
                          // forward snapshot to any listeners by emitting a custom event
                          try { frameObj._lastSnapshot = d.dataUrl || null; frameObj._failCount = 0; } catch (_) {}
                          console.debug('mcbaise:port:snapshot', { len: (d.dataUrl || '').length });
                        } else {
                          // child -> parent messages on the port if needed
                          console.debug('mcbaise:port:message', ev.data);
                        }
                      } catch (e) { console.debug('mcbaise:port:onmessage:error', e); }
                    };
                    // Send an immediate ping and then periodically refresh the estimate.
                    const sendPing = () => {
                      try {
                        const id = Math.random().toString(36).slice(2);
                        const t_parent_send_ms = Date.now();
                        frameObj._lastPingId = id;
                        frameObj._lastPingSentMs = t_parent_send_ms;
                        try { frameObj.port.postMessage({ type: 'ping', id, t_parent_send_ms }); } catch (_) {}
                      } catch (_) {}
                    };
                    // initial ping
                    sendPing();
                    try { frameObj._pingInterval = setInterval(sendPing, 5000); } catch (_) {}
                  } catch (_) {}
            }
          } catch (_) {}
          // Send an initial time and visibility sample after load.
          try {
            const t = playerReady ? (player?.getCurrentTime?.() ?? 0) : 0;
            // Prefer port-based delivery, fallback to postMessage
              if (frameObj.port && typeof frameObj.port.postMessage === 'function') {
                  frameObj.port.postMessage({ type: 'sync', timeSec: t, playing: !!isPlaying, rate: (player?.getPlaybackRate?.() ?? 1), parent_ts_ms: Date.now() });
                  try { frameObj._lastSeen = Date.now(); } catch (_) {}
              frameObj.port.postMessage({ type: 'mcbaise_set_video_visible', show: !(playerWrapEl && playerWrapEl.classList.contains('hidePlayer')) });
            } else {
                  _postToFrame(frameObj, { type: 'sync', timeSec: t, playing: !!isPlaying, rate: (player?.getPlaybackRate?.() ?? 1), parent_ts_ms: Date.now() });
                  try { frameObj._lastSeen = Date.now(); } catch (_) {}
              _postToFrame(frameObj, { type: 'mcbaise_set_video_visible', show: !(playerWrapEl && playerWrapEl.classList.contains('hidePlayer')) });
            }
          } catch (_) {}
        });

      // Push an initial time sample as soon as possible to already-loaded frames.
      const t = playerReady ? (player?.getCurrentTime?.() ?? 0) : 0;
      try { broadcastSync(t, !!isPlaying); } catch (_) { broadcastTime(t, !!isPlaying); }
    }


    async function main() {
      try {
        await bootWasm();
      } catch (err) {
        console.error(err);
        bootFailed = true;
        refreshLoading();
        throw err;
      }
      if (vizOnly) {
        // Viz-only iframe: no YouTube; parent will drive time via postMessage.
        ytReady = true;
        setYoutubeLoading(false, "");
        refreshLoading();
        if (videoPiContainer) videoPiContainer.style.display = "none";
        return;
      }

      // DOM controls were removed; the wasm app uses an egui overlay for runtime controls.
      setYoutubeLoading(true, "Loading YouTube…");
      await loadScript("https://www.youtube.com/iframe_api");
    }

    // Parent-level precise UI removed: children always interpolate locally.

    // Wire up directional pi buttons to inject viz in that cardinal direction.
    if (videoPiContainer) {
      const btns = videoPiContainer.querySelectorAll('.videoPi[data-dir]');
      btns.forEach(b => {
        b.addEventListener('click', (ev) => {
          const dir = b.dataset.dir || 'right';
          injectExtraViz(dir);
        });
      });
    }

    main().catch(err => console.error(err));
  </script>
  <script src="gif.js"></script>
  <script>
    // Helper: detect mostly-black dataURL images to avoid recording blank frames.
    // (Ported from index_better_no_blackframes.html)
    async function isMostlyBlackDataUrl(dataUrl, sampleSize = 64, blackThreshold = 0.96) {
      try {
        const img = new Image();
        await new Promise((res, rej) => { img.onload = res; img.onerror = rej; img.src = dataUrl; });
        const w = sampleSize;
        const h = sampleSize;
        const oc = document.createElement('canvas');
        oc.width = w;
        oc.height = h;
        const ctx = oc.getContext('2d', { willReadFrequently: true });
        ctx.drawImage(img, 0, 0, w, h);
        try {
          const id = ctx.getImageData(0, 0, w, h).data;
          let blackCount = 0;
          const total = w * h;
          for (let i = 0; i < id.length; i += 4) {
            const r = id[i], g = id[i + 1], b = id[i + 2], a = id[i + 3];
            if (a < 20) {
              // Treat fully transparent pixels as non-black but non-informative.
              continue;
            }
            const lum = (0.2126 * r + 0.7152 * g + 0.0722 * b) / 255;
            if (lum < 0.05) blackCount++;
          }
          const frac = blackCount / total;
          return frac >= blackThreshold;
        } catch (_) {
          // If reading pixels fails (tainting), assume not-black to avoid false positives.
          return false;
        }
      } catch (_) {
        return false;
      }
    }
    try { window.isMostlyBlackDataUrl = isMostlyBlackDataUrl; } catch (_) {}

    // Recording capture helpers: use compositor frames (captureStream/ImageCapture) when possible.
    // This tends to be far more reliable than `toDataURL` readback on WebGPU canvases.
    let _mcbaise_canvas_capture_cache = null;
    function _mcbaise_reset_canvas_capture_cache() {
      try {
        if (_mcbaise_canvas_capture_cache && _mcbaise_canvas_capture_cache.size) {
          for (const [, v] of _mcbaise_canvas_capture_cache.entries()) {
            try { v?.track?.stop?.(); } catch (_) {}
          }
        }
      } catch (_) {}
      _mcbaise_canvas_capture_cache = new Map();
    }

    async function _mcbaise_grab_canvas_frame_bitmap(canvas, fps = 30) {
      try {
        if (!(canvas instanceof HTMLCanvasElement)) return null;
        if (typeof canvas.captureStream !== 'function') return null;
        if (typeof window.ImageCapture !== 'function') return null;
        if (!_mcbaise_canvas_capture_cache) _mcbaise_reset_canvas_capture_cache();

        let entry = _mcbaise_canvas_capture_cache.get(canvas) || null;
        const dead = !entry || !entry.track || entry.track.readyState !== 'live';
        if (dead) {
          try { entry?.track?.stop?.(); } catch (_) {}
          const stream = canvas.captureStream(Math.max(1, fps));
          const track = stream && stream.getVideoTracks && stream.getVideoTracks()[0];
          if (!track) return null;
          const ic = new ImageCapture(track);
          entry = { stream, track, ic };
          _mcbaise_canvas_capture_cache.set(canvas, entry);
        }

        const bmp = await entry.ic.grabFrame();
        return bmp || null;
      } catch (_) {
        return null;
      }
    }

    let isRecording = false;
    let isFullscreenRecording = false;
    let frames = [];
    let recordInterval;
    let _mcbaise_single_record_fps = 10;
    let _mcbaise_full_record_fps = 5;
    // Keep last-good snapshots so we can reuse them when a tick returns a black/placeholder frame.
    let lastGoodSingleDataUrl = null;
    let lastGoodCompositeDataUrl = null;

    function _mcbaise_get_query_number(name, fallback) {
      try {
        const u = new URL(window.location.href);
        const v = u.searchParams.get(name);
        if (v == null || v === '') return fallback;
        const n = Number(v);
        return Number.isFinite(n) ? n : fallback;
      } catch (_) {
        return fallback;
      }
    }

    function _mcbaise_get_query_bool(name, fallback) {
      try {
        const u = new URL(window.location.href);
        const v = u.searchParams.get(name);
        if (v == null || v === '') return !!fallback;
        const s = String(v).trim().toLowerCase();
        if (s === '1' || s === 'true' || s === 'yes' || s === 'y' || s === 'on') return true;
        if (s === '0' || s === 'false' || s === 'no' || s === 'n' || s === 'off') return false;
        return !!fallback;
      } catch (_) {
        return !!fallback;
      }
    }

    // Recording FPS controls:
    // - `?recFps=15` sets both recorders unless overridden
    // - `?singleRecFps=15` / `?fullRecFps=10` override per-mode
    try {
      const base = _mcbaise_get_query_number('recFps', NaN);
      const single = _mcbaise_get_query_number('singleRecFps', Number.isFinite(base) ? base : _mcbaise_single_record_fps);
      const full = _mcbaise_get_query_number('fullRecFps', Number.isFinite(base) ? base : _mcbaise_full_record_fps);
      _mcbaise_single_record_fps = Math.max(1, Math.min(60, Math.round(single)));
      _mcbaise_full_record_fps = Math.max(1, Math.min(60, Math.round(full)));
      if (window.__MCBAISE_DEBUG) console.debug('mcbaise:record:fps', { single: _mcbaise_single_record_fps, full: _mcbaise_full_record_fps });
    } catch (_) {}

    // Optional lockstep recording:
    // - `?recLockstep=1` enables for both unless overridden
    // - `?fullRecLockstep=1` specifically enables fullscreen lockstep capture
    // Lockstep pauses/seeks to a target time per frame and waits for all panes.
    let _mcbaise_full_record_lockstep = false;
    try {
      const base = _mcbaise_get_query_bool('recLockstep', false);
      const full = _mcbaise_get_query_bool('fullRecLockstep', base);
      _mcbaise_full_record_lockstep = !!full;
      if (window.__MCBAISE_DEBUG) console.debug('mcbaise:record:lockstep', { full: _mcbaise_full_record_lockstep });
    } catch (_) {}

    console.log('GIF script loaded, attaching event listener');
    const gifIcon = document.getElementById('videoSingle');
    const fullscreenIcon = document.getElementById('videoFullscreen');

    // Encoding overlay + cancellation
    const encodeOverlayEl = document.getElementById('encodeOverlay');
    const encodeOverlayHdrEl = document.getElementById('encodeOverlayHdr');
    const encodeOverlayMsgEl = document.getElementById('encodeOverlayMsg');
    const encodeOverlayBarEl = document.getElementById('encodeOverlayBar');
    const encodeOverlayStopBtn = document.getElementById('encodeOverlayStop');
    let _mcbaise_cancel_encode = null;
    let _mcbaise_encode_active = false;

    function _mcbaise_show_encode_overlay(hdr, msg, progress01) {
      try {
        if (!encodeOverlayEl) return;
        encodeOverlayHdrEl.textContent = hdr || 'Encoding…';
        encodeOverlayMsgEl.textContent = msg || '';
        const p = Math.max(0, Math.min(1, Number(progress01) || 0));
        if (encodeOverlayBarEl) encodeOverlayBarEl.style.width = `${Math.round(p * 100)}%`;
        encodeOverlayEl.classList.add('show');
        try { encodeOverlayEl.setAttribute('aria-hidden', 'false'); } catch (_) {}
      } catch (_) {}
    }

    function _mcbaise_hide_encode_overlay() {
      try {
        if (!encodeOverlayEl) return;
        encodeOverlayEl.classList.remove('show');
        try { encodeOverlayEl.setAttribute('aria-hidden', 'true'); } catch (_) {}
        if (encodeOverlayBarEl) encodeOverlayBarEl.style.width = '0%';
      } catch (_) {}
    }

    try {
      if (encodeOverlayStopBtn) {
        encodeOverlayStopBtn.addEventListener('click', () => {
          try {
            if (typeof _mcbaise_cancel_encode === 'function') _mcbaise_cancel_encode('user');
          } catch (_) {}
        });
      }
    } catch (_) {}

    gifIcon.addEventListener('click', function() {
      if (isFullscreenRecording) return; // Don't allow both recordings
      if (!isRecording) {
        // Start recording
        isRecording = true;
        frames = [];
        gifIcon.textContent = 'stop';
        gifIcon.style.color = '#00ff00'; // Green when recording
        _mcbaise_reset_canvas_capture_cache();

        const loopToken = Date.now() + Math.random();
        try { window._mcbaise_single_record_token = loopToken; } catch (_) {}
        const fps = Math.max(1, _mcbaise_single_record_fps || 10);
        const intervalMs = Math.max(1, Math.round(1000 / fps));
        const startMs = (typeof performance !== 'undefined' && performance.now) ? performance.now() : Date.now();
        let frameIndex = 0; // how many frames we've committed to `frames`
        const tick = async () => {
          try {
            if (!isRecording) return;
            try { if (window._mcbaise_single_record_token !== loopToken) return; } catch (_) {}

            // Fixed-FPS scheduler:
            // Ensure we produce exactly one frame per ideal slot. If capture lags,
            // fill missed slots with the last-good frame so output duration matches
            // the requested FPS.
            const nowMs = (typeof performance !== 'undefined' && performance.now) ? performance.now() : Date.now();
            const expectedIndex = Math.max(0, Math.floor((nowMs - startMs) / intervalMs));
            const missing = expectedIndex - frameIndex;
            if (missing > 0 && lastGoodSingleDataUrl) {
              for (let i = 0; i < missing; i++) frames.push(lastGoodSingleDataUrl);
              frameIndex += missing;
              if (window.__MCBAISE_DEBUG) console.debug('mcbaise:record:single:filled-missed-frames', { missing, frameIndex, expectedIndex });
            }
            if (frameIndex > expectedIndex) {
              // We're early; wait until the next ideal slot.
              const nextMs = startMs + frameIndex * intervalMs;
              const waitMs = Math.max(0, Math.round(nextMs - nowMs));
              recordInterval = setTimeout(tick, waitMs);
              return;
            }

            const canvas = document.getElementById('bevy-canvas');
            if (canvas instanceof HTMLCanvasElement) {
              try {
                // Prefer compositor frame to avoid WebGPU readback blanks.
                let dataURL = null;
                try {
                  const bmp = await _mcbaise_grab_canvas_frame_bitmap(canvas, fps);
                  if (bmp) {
                    try {
                      const oc = document.createElement('canvas');
                      oc.width = bmp.width;
                      oc.height = bmp.height;
                      const octx = oc.getContext('2d', { willReadFrequently: true });
                      octx.drawImage(bmp, 0, 0);
                      dataURL = oc.toDataURL('image/png');
                    } finally {
                      try { bmp.close?.(); } catch (_) {}
                    }
                  }
                } catch (_) { dataURL = null; }

                if (!dataURL) {
                  try { dataURL = canvas.toDataURL('image/png'); } catch (_) { dataURL = null; }
                }

                if (dataURL && dataURL.length > 200) {
                  let isBlack = false;
                  try {
                    isBlack = await (window.isMostlyBlackDataUrl ? window.isMostlyBlackDataUrl(dataURL) : isMostlyBlackDataUrl(dataURL));
                  } catch (_) { isBlack = false; }
                  if (!isBlack) {
                    frames.push(dataURL);
                    lastGoodSingleDataUrl = dataURL;
                    frameIndex += 1;
                  } else if (lastGoodSingleDataUrl) {
                    frames.push(lastGoodSingleDataUrl);
                    frameIndex += 1;
                    if (window.__MCBAISE_DEBUG) console.debug('mcbaise:record:using-last-good-single-frame (mostly black)');
                  } else {
                    if (window.__MCBAISE_DEBUG) console.debug('mcbaise:record:skipping mostly-black single-canvas frame', { len: (dataURL || '').length });
                  }
                } else if (lastGoodSingleDataUrl) {
                  frames.push(lastGoodSingleDataUrl);
                  frameIndex += 1;
                  if (window.__MCBAISE_DEBUG) console.debug('mcbaise:record:using-last-good-single-frame');
                } else {
                  if (window.__MCBAISE_DEBUG) console.debug('mcbaise:record:skipping tiny single-canvas frame', { len: (dataURL || '').length });
                }
              } catch (e) {
                if (lastGoodSingleDataUrl) {
                  frames.push(lastGoodSingleDataUrl);
                  frameIndex += 1;
                  if (window.__MCBAISE_DEBUG) console.debug('mcbaise:record:single capture failed - using last good', e);
                } else {
                  if (window.__MCBAISE_DEBUG) console.debug('mcbaise:record:single capture failed', e);
                }
              }
            }
          } catch (_) {}
          try {
            if (!isRecording) return;
            try { if (window._mcbaise_single_record_token !== loopToken) return; } catch (_) {}
            const nowMs2 = (typeof performance !== 'undefined' && performance.now) ? performance.now() : Date.now();
            const nextMs = startMs + frameIndex * intervalMs;
            const waitMs = Math.max(0, Math.round(nextMs - nowMs2));
            recordInterval = setTimeout(tick, waitMs);
          } catch (_) {}
        };
        recordInterval = setTimeout(tick, 0);
      } else {
        // Stop recording and create GIF
        isRecording = false;
        try { clearTimeout(recordInterval); } catch (_) { try { clearInterval(recordInterval); } catch (_) {} }
        try { window._mcbaise_single_record_token = null; } catch (_) {}
        try { _mcbaise_reset_canvas_capture_cache(); } catch (_) {}
        gifIcon.textContent = 'videocam';
        gifIcon.style.color = '#cccccc'; // Back to light grey
        if (frames.length > 0) {
          createGIF(frames, { fps: _mcbaise_single_record_fps });
        }
      }
    });

    fullscreenIcon.addEventListener('click', function() {
      if (isRecording) return; // Don't allow both recordings
      if (!isFullscreenRecording) {
        // Start fullscreen recording
        isFullscreenRecording = true;
        frames = [];
        fullscreenIcon.textContent = 'stop';
        fullscreenIcon.style.color = '#00ff00'; // Green when recording
        _mcbaise_reset_canvas_capture_cache();

        const loopToken = Date.now() + Math.random();
        try { window._mcbaise_full_record_token = loopToken; } catch (_) {}
        const fps = Math.max(1, _mcbaise_full_record_fps || 5);
        const intervalMs = Math.max(1, Math.round(1000 / fps));
        const lockstep = !!_mcbaise_full_record_lockstep;

        if (lockstep) {
          try {
            const p = (typeof window !== 'undefined') ? window._mcbaise_player : null;
            try { p?.playVideo?.(); } catch (_) {}
          } catch (_) {}
        }

        const startMs = (typeof performance !== 'undefined' && performance.now) ? performance.now() : Date.now();
        let frameIndex = 0; // how many frames we've committed to `frames`
        let lockstepRetry = 0;
        let lockstepForcePause = false;
        let lockstepFrameTimeSec = null;
        let lockstepFrameSyncId = null;

        async function _mcbaise_wait_for_player_time(targetSec, timeoutMs = 2500, epsSec = 0.06) {
          try {
            const t0 = performance.now();
            while ((performance.now() - t0) < timeoutMs) {
              const p = (typeof window !== 'undefined') ? window._mcbaise_player : null;
              const t = (p && typeof p.getCurrentTime === 'function') ? Number(p.getCurrentTime() || 0) : NaN;
              if (Number.isFinite(t) && Math.abs(t - targetSec) <= epsSec) return true;
              // eslint-disable-next-line no-await-in-loop
              await new Promise(r => setTimeout(r, 40));
            }
          } catch (_) {}
          return false;
        }

        const tick = async () => {
          try {
            if (!isFullscreenRecording) return;
            try { if (window._mcbaise_full_record_token !== loopToken) return; } catch (_) {}

            // Shared capture time/syncId for this frame.
            const captureSyncId = lockstep
              ? (lockstepFrameSyncId || (lockstepFrameSyncId = (Date.now().toString(36) + '-' + frameIndex.toString(36) + '-' + Math.random().toString(36).slice(2, 8))))
              : (Date.now().toString(36) + '-' + frameIndex.toString(36) + '-' + Math.random().toString(36).slice(2, 8));
            let captureTimeSec = 0;
            let capturePlaying = false;

            if (lockstep) {
              // Lockstep barrier while keeping playback overall:
              // 1) Ensure video is playing.
              // 2) Sample current time.
              // 3) Briefly pause + broadcast a paused sync so every pane captures *the same time*.
              // 4) Capture snapshots.
              // 5) Resume play.
              const p = (typeof window !== 'undefined') ? window._mcbaise_player : null;

              try { p?.playVideo?.(); } catch (_) {}

              try {
                if (lockstepFrameTimeSec == null) {
                  const tNow = (p && typeof p.getCurrentTime === 'function') ? Number(p.getCurrentTime() || 0) : 0;
                  lockstepFrameTimeSec = Number.isFinite(tNow) ? tNow : 0;
                }
                captureTimeSec = Number(lockstepFrameTimeSec) || 0;
              } catch (_) {
                captureTimeSec = 0;
              }

              // Only pause if we previously detected a lagging pane on this frame.
              if (lockstepForcePause) {
                try { p?.pauseVideo?.(); } catch (_) {}
              }
              capturePlaying = false;

              try {
                const setTime = (typeof window !== 'undefined') ? window._mcbaise_scheduleWasmSetVideoTime : null;
                if (typeof setTime === 'function') setTime(captureTimeSec, false);
              } catch (_) {}
              try {
                const bsync = (typeof window !== 'undefined') ? window._mcbaise_broadcastSync : null;
                if (typeof bsync === 'function') bsync(captureTimeSec, false);
              } catch (_) {}

              await new Promise((res) => requestAnimationFrame(() => requestAnimationFrame(res)));
            } else {
              const _ps = (typeof window._mcbaise_getPlayerState === 'function') ? window._mcbaise_getPlayerState() : null;
              captureTimeSec = (_ps && _ps.playerReady) ? (Number(_ps.timeSec) || 0) : 0;
              capturePlaying = (_ps && _ps.playerReady) ? !!_ps.playing : false;

              // Nudge all children toward the same time before requesting snapshots.
              try {
                const bsync = (typeof window._mcbaise_broadcastSync === 'function') ? window._mcbaise_broadcastSync : (typeof broadcastSync === 'function' ? broadcastSync : null);
                if (bsync) bsync(captureTimeSec, capturePlaying);
              } catch (_) {}
            }

            if (!lockstep) {
              // Fixed-FPS scheduler (see single-canvas recorder for rationale)
              const nowMs = (typeof performance !== 'undefined' && performance.now) ? performance.now() : Date.now();
              const expectedIndex = Math.max(0, Math.floor((nowMs - startMs) / intervalMs));
              const missing = expectedIndex - frameIndex;
              if (missing > 0 && lastGoodCompositeDataUrl) {
                for (let i = 0; i < missing; i++) frames.push(lastGoodCompositeDataUrl);
                frameIndex += missing;
                if (window.__MCBAISE_DEBUG) console.debug('mcbaise:record:full:filled-missed-frames', { missing, frameIndex, expectedIndex });
              }
              if (frameIndex > expectedIndex) {
                const nextMs = startMs + frameIndex * intervalMs;
                const waitMs = Math.max(0, Math.round(nextMs - nowMs));
                recordInterval = setTimeout(tick, waitMs);
                return;
              }
            }

            // Use page dimensions so we can place multiple canvases by absolute page position.
            const pageRect = document.documentElement.getBoundingClientRect();
            const totalWidth = Math.max(1, Math.ceil(pageRect.width));
            const totalHeight = Math.max(1, Math.ceil(pageRect.height));

            const composite = document.createElement('canvas');
            composite.width = totalWidth;
            composite.height = totalHeight;
            const ctx = composite.getContext('2d', { willReadFrequently: true });
            // Black background
            ctx.fillStyle = '#000000';
            ctx.fillRect(0, 0, composite.width, composite.height);

            // Left column layout: draw placeholder only in the actual player area(s)
            const leftElement = document.getElementById('left');
            const playerWrap = document.getElementById('playerWrap');
            const leftExtras = leftElement ? Array.from(leftElement.querySelectorAll('.extraViz, #playerWrap')) : [];
            ctx.fillStyle = '#ffffff';
            ctx.textAlign = 'center';
            ctx.textBaseline = 'middle';
            const fontSize = Math.max(12, Math.round(Math.min(32, totalHeight * 0.06)));
            ctx.font = `${fontSize}px sans-serif`;
            const videoTitle = (typeof player !== 'undefined' && player && typeof player.getVideoData === 'function') ? (player.getVideoData().title || '') : '';
            const leftLines = [PROJECT_NAME, `YOUTUBE ${window.VIDEO_ID}${videoTitle ? ' - ' + videoTitle : ''}`];
            const lineH = fontSize * 1.15;

            if (playerWrap) {
              try {
                const pRect = playerWrap.getBoundingClientRect();
                ctx.fillStyle = '#111111';
                ctx.fillRect(Math.round(pRect.left), Math.round(pRect.top), Math.round(pRect.width), Math.round(pRect.height));
                // Auto-scale font so each line fits within the player width with padding.
                try {
                  const paddingX = Math.max(8, Math.round(pRect.width * 0.06));
                  const maxWidth = Math.max(20, Math.round(pRect.width - paddingX * 2));
                  let fs = fontSize;
                  ctx.font = `${fs}px sans-serif`;
                  while (fs > 10) {
                    let ok = true;
                    for (let li = 0; li < leftLines.length; li++) {
                      const w = ctx.measureText(leftLines[li]).width;
                      if (w > maxWidth) { ok = false; break; }
                    }
                    if (ok) break;
                    fs -= 1;
                    ctx.font = `${fs}px sans-serif`;
                  }
                  const adjLineH = fs * 1.15;
                  const startY = pRect.top + pRect.height / 2 - (leftLines.length - 1) * adjLineH / 2;
                  for (let i = 0; i < leftLines.length; i++) {
                    ctx.fillStyle = '#ffffff';
                    ctx.fillText(leftLines[i], Math.round(pRect.left + pRect.width / 2), Math.round(startY + i * adjLineH));
                  }
                } catch (_) {
                  const startY = pRect.top + pRect.height / 2 - (leftLines.length - 1) * lineH / 2;
                  for (let i = 0; i < leftLines.length; i++) {
                    ctx.fillStyle = '#ffffff';
                    ctx.fillText(leftLines[i], Math.round(pRect.left + pRect.width / 2), Math.round(startY + i * lineH));
                  }
                }
              } catch (_) {}
            }

            // If there are extra viz panes in the left column, draw smaller placeholders
            // only when an iframe has repeatedly failed to provide a real snapshot.
            let _drewExtraVizPlaceholder = false;
            try {
              const extras = leftElement ? leftElement.querySelectorAll('.extraViz') : null;
              if (extras && extras.length) {
                extras.forEach(ex => {
                  try {
                    const er = ex.getBoundingClientRect();
                    const iframe = ex.querySelector && ex.querySelector('iframe');
                    const framesList = (typeof extraVizFrames !== 'undefined' && Array.isArray(extraVizFrames))
                      ? extraVizFrames
                      : (Array.isArray(window._mcbaise_extraVizFrames) ? window._mcbaise_extraVizFrames : []);
                    let frameObj = null;
                    try {
                      if (iframe) frameObj = framesList.find(f => f.iframe === iframe) || framesList.find(f => f.iframe && f.iframe.contentWindow === iframe.contentWindow) || framesList.find(f => f.iframe && f.iframe.src === iframe.src) || null;
                    } catch (_) { frameObj = null; }
                    const failCount = (frameObj && frameObj._failCount) || 0;
                    const hasSnapshot = !!(frameObj && frameObj._lastSnapshot);
                    // If we have a recent snapshot or haven't failed enough times, skip the placeholder.
                    // In debug, show placeholder immediately so black regions are diagnosable.
                    if (hasSnapshot || (!window.__MCBAISE_DEBUG && failCount < 3)) return;
                    ctx.fillStyle = '#0b0b0b';
                    ctx.fillRect(Math.round(er.left), Math.round(er.top), Math.round(er.width), Math.round(er.height));
                    ctx.fillStyle = '#ffffff';
                    ctx.fillText('EXTRA VIZ (no snapshot)', Math.round(er.left + er.width / 2), Math.round(er.top + er.height / 2));
                    _drewExtraVizPlaceholder = true;
                  } catch (_) {}
                });
              }
            } catch (_) {}

            // Collect capture targets (canvases) and their page rects.
            const targets = [];

            // Prefer explicit `#bevy-canvas` in this document
            const bevyCanvas = document.getElementById('bevy-canvas');
            if (bevyCanvas instanceof HTMLCanvasElement) {
              targets.push({ canvas: bevyCanvas, rect: bevyCanvas.getBoundingClientRect(), fromIframe: false });
            }

            // Any canvases inside the right pane
            const rightElement = document.getElementById('right');
            if (rightElement) {
              const canvases = rightElement.querySelectorAll('canvas');
              canvases.forEach(c => { if (c instanceof HTMLCanvasElement && c !== bevyCanvas) targets.push({ canvas: c, rect: c.getBoundingClientRect(), fromIframe: false }); });
            }

            // Attempt to capture canvases inside same-origin `.extraViz` iframes.
            const extraIframes = document.querySelectorAll('.extraViz iframe');
            // Helper: request a snapshot from an iframe.
            // - Preferred: wasm GPU readback (`wasm_pixels` postMessage)
            // - Fallbacks: ImageBitmap (`wasm_imagebitmap`) or legacy `{type:'snapshot', dataUrl}`
            async function requestIframeSnapshot(iframe, req) {
              try {
                const reqSyncId = (req && req.syncId != null) ? String(req.syncId) : null;
                const reqTimeSec = (req && req.timeSec != null) ? Number(req.timeSec) : null;
                const reqPlaying = !!(req && req.playing);
                const timeoutMs = Math.max(250, Math.round(Number(req && req.timeoutMs) || 3000));
                const strict = !!(req && req.strict);

                let iframeWin = null;
                try { iframeWin = iframe && iframe.contentWindow; } catch (_) { iframeWin = null; }

                // Prefer our tracked `extraVizFrames` which may hold a MessagePort.
                // Guard against ReferenceError when `extraVizFrames` isn't in this scope
                // (use typeof checks and fall back to window-exposed array).
                const framesList = (typeof extraVizFrames !== 'undefined' && Array.isArray(extraVizFrames))
                  ? extraVizFrames
                  : (Array.isArray(window._mcbaise_extraVizFrames) ? window._mcbaise_extraVizFrames : (Array.isArray(window.extraVizFrames) ? window.extraVizFrames : []));
                let frameObj = framesList.find(f => f.iframe === iframe) || null;
                // If the exact iframe object wasn't matched (e.g. different but same src), try matching by contentWindow or src
                if (!frameObj) {
                  try {
                    frameObj = framesList.find(f => f.iframe && f.iframe.contentWindow === iframe.contentWindow) || frameObj;
                  } catch (_) {}
                  try {
                    const src = iframe && iframe.src;
                    if (!frameObj && src) frameObj = framesList.find(f => f.iframe && f.iframe.src === src) || null;
                  } catch (_) {}
                }
                // If a MessagePort is available, request snapshot through it. If not yet attached, wait briefly for it.
                if (frameObj) {
                  // wait up to 700ms for port readiness
                  const start = performance.now();
                  while ((!frameObj.port || typeof frameObj.port.postMessage !== 'function') && (performance.now() - start) < 700) {
                    await new Promise(r => setTimeout(r, 60));
                  }
                  if (frameObj.port && typeof frameObj.port.postMessage === 'function') {
                    try {
                      return await new Promise((resolve) => {
                        let resolved = false;
                        let gotTriggerAck = false;
                        const finish = (val) => {
                          if (resolved) return;
                          resolved = true;
                          try { frameObj.port.removeEventListener('message', onport); } catch (_) {}
                          try { window.removeEventListener('message', onwin); } catch (_) {}
                          try {
                            if (frameObj && reqSyncId != null && frameObj._pendingSnapshotSyncId === reqSyncId) frameObj._pendingSnapshotSyncId = null;
                          } catch (_) {}
                          try {
                            // Cache last-good snapshot for this iframe (used when a request times out).
                            // Cache only pixels/dataUrl; ImageBitmaps are typically single-use.
                            if (frameObj && val && (val.kind === 'pixels' || val.kind === 'dataUrl')) {
                              frameObj._lastSnapshot = val;
                              frameObj._lastSnapshotTsMs = performance.now();
                            }
                          } catch (_) {}
                          resolve(val);
                        };

                        const onwin = (ev) => {
                          try {
                            if (iframeWin && ev.source !== iframeWin) return;
                            const d = ev.data;
                            if (!d || typeof d !== 'object') return;

                            if (d.type === 'wasm_pixels' && d.pixels && d.width && d.height) {
                              // If the wasm message includes correlation fields, enforce them.
                              if (reqSyncId != null && d.syncId != null && String(d.syncId) !== reqSyncId) return;
                              // If the wasm message does NOT include correlation fields, only accept it
                              // after we saw a trigger ack for this request.
                              if (reqSyncId != null && d.syncId == null && !gotTriggerAck) return;
                              // If we set a pending syncId for this iframe, only accept pixels while pending.
                              try { if (reqSyncId != null && frameObj && frameObj._pendingSnapshotSyncId && frameObj._pendingSnapshotSyncId !== reqSyncId) return; } catch (_) {}
                              if (window.__MCBAISE_DEBUG) console.debug('mcbaise:iframe:wasm_pixels', { w: d.width, h: d.height, gpu: !!d.gpu, checksum: d.checksum });
                              finish({ kind: 'pixels', pixels: d.pixels, width: Number(d.width) || 0, height: Number(d.height) || 0, checksum: (d.checksum != null) ? Number(d.checksum) : null, gpu: !!d.gpu, sample: d.sample || null });
                              return;
                            }
                            if (d.type === 'wasm_imagebitmap' && d.bitmap) {
                              finish({ kind: 'bitmap', bitmap: d.bitmap });
                              return;
                            }
                            if (d.type === 'snapshot') {
                              if (reqSyncId != null && String(d.syncId || '') !== reqSyncId) return;
                              finish({ kind: 'dataUrl', dataUrl: d.dataUrl || null });
                              return;
                            }
                            if (d.type === 'snapshot_gpu_triggered') {
                              // Acknowledgement that the child started a GPU readback for this request.
                              if (reqSyncId != null && String(d.syncId || '') !== reqSyncId) return;
                              gotTriggerAck = true;
                              try { if (frameObj && reqSyncId != null) frameObj._pendingSnapshotSyncId = reqSyncId; } catch (_) {}
                              return;
                            }
                          } catch (_) {}
                        };

                        const onport = (ev) => {
                          try {
                            const d = ev.data;
                            if (d && d.type === 'snapshot') {
                              if (reqSyncId != null && String(d.syncId || '') !== reqSyncId) return;
                              finish({ kind: 'dataUrl', dataUrl: d.dataUrl || null });
                            }
                          } catch (_) {}
                        };

                        try { window.addEventListener('message', onwin); } catch (_) {}
                        try { frameObj.port.addEventListener('message', onport); } catch (_) {}
                        try { if (frameObj && reqSyncId != null) frameObj._pendingSnapshotSyncId = reqSyncId; } catch (_) {}
                        try { frameObj.port.postMessage({ type: 'request_snapshot', syncId: reqSyncId, timeSec: reqTimeSec, playing: reqPlaying }); } catch (_) {}
                        setTimeout(() => {
                          if (!resolved) {
                            resolved = true;
                            try { frameObj.port.removeEventListener('message', onport); } catch (_) {}
                            try { window.removeEventListener('message', onwin); } catch (_) {}
                            try { if (frameObj && reqSyncId != null && frameObj._pendingSnapshotSyncId === reqSyncId) frameObj._pendingSnapshotSyncId = null; } catch (_) {}
                            resolve(null);
                          }
                        }, timeoutMs);
                      });
                    } catch (e) { if (window.__MCBAISE_DEBUG) console.debug('port snapshot request failed', e); }
                  }
                }

                // Fallback: if same-origin, postMessage to contentWindow and wait for a reply
                try {
                  const win = iframe.contentWindow;
                  if (win && iframe.contentDocument) {
                    try {
                      return await new Promise((resolve) => {
                        let resolved = false;
                        let gotTriggerAck = false;
                        const finish = (val) => {
                          if (resolved) return;
                          resolved = true;
                          try { window.removeEventListener('message', onmsg); } catch (_) {}
                          try {
                            if (frameObj && reqSyncId != null && frameObj._pendingSnapshotSyncId === reqSyncId) frameObj._pendingSnapshotSyncId = null;
                          } catch (_) {}
                          try {
                            if (frameObj && val && (val.kind === 'pixels' || val.kind === 'dataUrl')) {
                              frameObj._lastSnapshot = val;
                              frameObj._lastSnapshotTsMs = performance.now();
                            }
                          } catch (_) {}
                          resolve(val);
                        };

                        const onmsg = (ev) => {
                          try {
                            if (ev.source !== win) return;
                            const d = ev.data;
                            if (!d || typeof d !== 'object') return;

                            if (d.type === 'wasm_pixels' && d.pixels && d.width && d.height) {
                              if (reqSyncId != null && d.syncId != null && String(d.syncId) !== reqSyncId) return;
                              if (reqSyncId != null && d.syncId == null && !gotTriggerAck) return;
                              try { if (reqSyncId != null && frameObj && frameObj._pendingSnapshotSyncId && frameObj._pendingSnapshotSyncId !== reqSyncId) return; } catch (_) {}
                              if (window.__MCBAISE_DEBUG) console.debug('mcbaise:iframe:wasm_pixels', { w: d.width, h: d.height, gpu: !!d.gpu, checksum: d.checksum });
                              finish({ kind: 'pixels', pixels: d.pixels, width: Number(d.width) || 0, height: Number(d.height) || 0, checksum: (d.checksum != null) ? Number(d.checksum) : null, gpu: !!d.gpu, sample: d.sample || null });
                              return;
                            }
                            if (d.type === 'wasm_imagebitmap' && d.bitmap) {
                              finish({ kind: 'bitmap', bitmap: d.bitmap });
                              return;
                            }
                            if (d.type === 'snapshot') {
                              if (reqSyncId != null && String(d.syncId || '') !== reqSyncId) return;
                              finish({ kind: 'dataUrl', dataUrl: d.dataUrl || null });
                              return;
                            }
                            if (d.type === 'snapshot_gpu_triggered') {
                              if (reqSyncId != null && String(d.syncId || '') !== reqSyncId) return;
                              gotTriggerAck = true;
                              try { if (frameObj && reqSyncId != null) frameObj._pendingSnapshotSyncId = reqSyncId; } catch (_) {}
                              return;
                            }
                          } catch (_) {}
                        };

                        window.addEventListener('message', onmsg);
                        try { if (frameObj && reqSyncId != null) frameObj._pendingSnapshotSyncId = reqSyncId; } catch (_) {}
                        const msg = { type: 'request_snapshot', syncId: reqSyncId, timeSec: reqTimeSec, playing: reqPlaying };
                        try { win.postMessage(msg, PAGE_ORIGIN); } catch (e) { try { win.postMessage(msg, '*'); } catch (_) {} }
                        setTimeout(() => {
                          if (!resolved) {
                            resolved = true;
                            window.removeEventListener('message', onmsg);
                            try { if (frameObj && reqSyncId != null && frameObj._pendingSnapshotSyncId === reqSyncId) frameObj._pendingSnapshotSyncId = null; } catch (_) {}
                            resolve(null);
                          }
                        }, timeoutMs);
                      });
                    } catch (e) { if (window.__MCBAISE_DEBUG) console.debug('iframe postMessage request failed', e); }
                  }
                } catch (e) {
                  if (window.__MCBAISE_DEBUG) console.debug('iframe snapshot postMessage failed', e);
                }
              } catch (e) {
                if (window.__MCBAISE_DEBUG) console.debug('requestIframeSnapshot error', e);
              }
              // If we have a tracked frame object, increment a failure counter so
              // the UI can decide whether to render a placeholder caption.
              try { if (frameObj) frameObj._failCount = (frameObj._failCount || 0) + 1; } catch (_) {}

              // If the request failed/timed out, reuse last-good snapshot (if any)
              // unless the caller asked for strict lockstep.
              if (!strict) {
                try {
                  if (frameObj && frameObj._lastSnapshot) {
                    return frameObj._lastSnapshot;
                  }
                } catch (_) {}
              }
              return null;
            }

            const iframeList = Array.from(extraIframes || []).map(ifr => ({ iframe: ifr, rect: ifr.getBoundingClientRect() }));

            if (lockstep) {
              // Optimistic: request snapshots while video is still playing. If any iframe doesn't
              // respond quickly, escalate to a pause+retry barrier for this same frame.
              const optimisticTimeoutMs = lockstepForcePause ? 10000 : 350;
              const snaps = await Promise.all(iframeList.map(ent => requestIframeSnapshot(ent.iframe, {
                syncId: captureSyncId,
                timeSec: captureTimeSec,
                playing: capturePlaying,
                timeoutMs: optimisticTimeoutMs,
                strict: true,
              })));

              for (let i = 0; i < iframeList.length; i++) {
                const ent = iframeList[i];
                const snap = snaps[i];

                if (!snap) {
                  lockstepRetry = (lockstepRetry || 0) + 1;
                  if (!lockstepForcePause) lockstepForcePause = true;
                  if (lockstepRetry <= 80) {
                    if (window.__MCBAISE_DEBUG) console.warn('mcbaise:record:lockstep:missing-iframe-snapshot:retry', { frameIndex, retry: lockstepRetry, forcedPause: lockstepForcePause });
                    throw new Error('mcbaise_lockstep_retry');
                  }
                  if (window.__MCBAISE_DEBUG) console.warn('mcbaise:record:lockstep:missing-iframe-snapshot:gave-up', { frameIndex, retry: lockstepRetry });
                  continue;
                }

                if (snap.kind === 'dataUrl' && snap.dataUrl) {
                  try {
                    const img = new Image();
                    await new Promise((res, rej) => { img.onload = res; img.onerror = rej; img.src = snap.dataUrl; });
                    targets.push({ img, rect: ent.rect, fromIframe: true, isImage: true });
                    continue;
                  } catch (e) {
                    if (window.__MCBAISE_DEBUG) console.debug('failed to load snapshot image', e);
                    lockstepRetry = (lockstepRetry || 0) + 1;
                    if (!lockstepForcePause) lockstepForcePause = true;
                    throw new Error('mcbaise_lockstep_retry');
                  }
                }

                if (snap.kind === 'bitmap' && snap.bitmap) {
                  targets.push({ bitmap: snap.bitmap, rect: ent.rect, fromIframe: true, isBitmap: true });
                  continue;
                }

                if (snap.kind === 'pixels' && snap.pixels && snap.width && snap.height) {
                  const cs = (snap.checksum != null) ? Number(snap.checksum) : null;
                  if (cs !== 0) {
                    targets.push({ pixels: snap.pixels, pw: snap.width, ph: snap.height, rect: ent.rect, fromIframe: true, isPixels: true, gpu: !!snap.gpu, checksum: cs, sample: snap.sample || null });
                    continue;
                  }
                  // checksum==0 likely blank => retry.
                  lockstepRetry = (lockstepRetry || 0) + 1;
                  if (!lockstepForcePause) lockstepForcePause = true;
                  throw new Error('mcbaise_lockstep_retry');
                }
              }
            } else {
              for (const ent of iframeList) {
                try {
                  const snap = await requestIframeSnapshot(ent.iframe, { syncId: captureSyncId, timeSec: captureTimeSec, playing: capturePlaying });
                  if (snap && snap.kind === 'dataUrl' && snap.dataUrl) {
                    try {
                      const img = new Image();
                      await new Promise((res, rej) => { img.onload = res; img.onerror = rej; img.src = snap.dataUrl; });
                      targets.push({ img, rect: ent.rect, fromIframe: true, isImage: true });
                      continue;
                    } catch (e) {
                      if (window.__MCBAISE_DEBUG) console.debug('failed to load snapshot image', e);
                    }
                  }
                  if (snap && snap.kind === 'bitmap' && snap.bitmap) {
                    targets.push({ bitmap: snap.bitmap, rect: ent.rect, fromIframe: true, isBitmap: true });
                    continue;
                  }
                  if (snap && snap.kind === 'pixels' && snap.pixels && snap.width && snap.height) {
                    const cs = (snap.checksum != null) ? Number(snap.checksum) : null;
                    if (cs !== 0) {
                      targets.push({ pixels: snap.pixels, pw: snap.width, ph: snap.height, rect: ent.rect, fromIframe: true, isPixels: true, gpu: !!snap.gpu, checksum: cs, sample: snap.sample || null });
                      continue;
                    }
                  }
                } catch (e) {
                  if (window.__MCBAISE_DEBUG) console.debug('extra iframe handling failed', e);
                }
              }
            }

            // Draw all targets into the composite at their page positions.
            let _missingTarget = false;
            let _drawnTargets = 0;
            const _pixelsScratchCanvas = document.createElement('canvas');
            const _pixelsScratchCtx = _pixelsScratchCanvas.getContext('2d', { willReadFrequently: true });
            for (const t of targets) {
              try {
                const r = t.rect;
                // If this target is an image (snapshot from iframe), draw it directly.
                if (t.isImage && t.img) {
                  try {
                    ctx.drawImage(t.img, 0, 0, t.img.width || Math.round(r.width), t.img.height || Math.round(r.height), Math.round(r.left), Math.round(r.top), Math.round(r.width), Math.round(r.height));
                    _drawnTargets += 1;
                    if (window.__MCBAISE_DEBUG) console.debug('mcbaise:record:target:image', { fromIframe: !!t.fromIframe, rect: r, imgWidth: t.img.width, imgHeight: t.img.height });
                    continue;
                  } catch (e) {
                    if (window.__MCBAISE_DEBUG) console.debug('drawImage(snapshot) failed', e);
                  }
                  _missingTarget = true;
                  continue;
                }

                // If this target is a transferred ImageBitmap, draw it and close.
                if (t.isBitmap && t.bitmap) {
                  try {
                    ctx.drawImage(t.bitmap, 0, 0, t.bitmap.width || Math.round(r.width), t.bitmap.height || Math.round(r.height), Math.round(r.left), Math.round(r.top), Math.round(r.width), Math.round(r.height));
                    _drawnTargets += 1;
                    try { t.bitmap.close?.(); } catch (_) {}
                    continue;
                  } catch (_) {
                    try { t.bitmap.close?.(); } catch (_) {}
                  }
                  _missingTarget = true;
                  continue;
                }

                // If this target is raw RGBA pixels from wasm GPU readback, blit via a scratch canvas.
                if (t.isPixels && t.pixels && _pixelsScratchCtx) {
                  try {
                    const pw = Math.max(1, (Number(t.pw) || 0) | 0);
                    const ph = Math.max(1, (Number(t.ph) || 0) | 0);
                    const expectedLen = pw * ph * 4;
                    const arr = new Uint8ClampedArray(t.pixels);
                    if (arr && arr.length === expectedLen) {
                      if (_pixelsScratchCanvas.width !== pw) _pixelsScratchCanvas.width = pw;
                      if (_pixelsScratchCanvas.height !== ph) _pixelsScratchCanvas.height = ph;
                      const imgData = new ImageData(arr, pw, ph);
                      _pixelsScratchCtx.putImageData(imgData, 0, 0);
                      ctx.drawImage(_pixelsScratchCanvas, Math.round(r.left), Math.round(r.top), Math.round(r.width), Math.round(r.height));
                      _drawnTargets += 1;
                      continue;
                    }
                  } catch (_) {}
                  _missingTarget = true;
                  continue;
                }

                // For the main in-document Bevy canvas, prefer compositor frames.
                // This avoids the common WebGPU blank-frame failure mode with `toDataURL`.
                try {
                  const isMainBevy = (!t.fromIframe && t.canvas && t.canvas.id === 'bevy-canvas');
                  if (isMainBevy) {
                    const bmp = await _mcbaise_grab_canvas_frame_bitmap(t.canvas, fps);
                    if (bmp) {
                      try {
                        ctx.drawImage(bmp, 0, 0, bmp.width, bmp.height, Math.round(r.left), Math.round(r.top), Math.round(r.width), Math.round(r.height));
                        _drawnTargets += 1;
                        continue;
                      } finally {
                        try { bmp.close?.(); } catch (_) {}
                      }
                    }
                  }
                } catch (_) {}

                // Debug: attempt a `toDataURL` to detect tainting / read errors on canvas targets.
                let toDataUrlOk = false;
                try {
                  const _d = t.canvas.toDataURL('image/png');
                  toDataUrlOk = !!(_d && _d.length > 100);
                } catch (e) {
                  if (window.__MCBAISE_DEBUG) console.debug('toDataURL failed for target canvas', e);
                  toDataUrlOk = false;
                }
                if (window.__MCBAISE_DEBUG) console.debug('mcbaise:record:target', { fromIframe: !!t.fromIframe, toDataUrlOk, canvasWidth: t.canvas?.width, canvasHeight: t.canvas?.height, rect: r });
                // Use explicit source size to avoid implicit CSS->bitmap scaling issues.
                const srcW = (t.canvas && t.canvas.width) || Math.round(r.width);
                const srcH = (t.canvas && t.canvas.height) || Math.round(r.height);
                // If toDataURL failed or canvas is WebGL without preserved buffer, try ImageBitmap fallback
                // then a captureStream+ImageCapture grabFrame fallback. If all fail, fall back to direct draw (may be black).
                let drawn = false;
                try {
                  if (toDataUrlOk) {
                    try {
                      // Prefer drawing a decoded image from the canvas dataURL — mirrors single-canvas capture flow.
                      const durl = t.canvas.toDataURL('image/png');
                      const img = new Image();
                      await new Promise((res, rej) => { img.onload = res; img.onerror = rej; img.src = durl; });
                      ctx.drawImage(img, 0, 0, img.naturalWidth || srcW, img.naturalHeight || srcH, Math.round(r.left), Math.round(r.top), Math.round(r.width), Math.round(r.height));
                      drawn = true;
                    } catch (e) {
                      if (window.__MCBAISE_DEBUG) console.debug('draw from dataURL failed, falling back to canvas draw', e);
                      try { ctx.drawImage(t.canvas, 0, 0, srcW, srcH, Math.round(r.left), Math.round(r.top), Math.round(r.width), Math.round(r.height)); drawn = true; } catch (_) {}
                    }
                  } else {
                    if (typeof createImageBitmap === 'function') {
                      try {
                        const bitmap = await createImageBitmap(t.canvas);
                        ctx.drawImage(bitmap, 0, 0, bitmap.width, bitmap.height, Math.round(r.left), Math.round(r.top), Math.round(r.width), Math.round(r.height));
                        try { bitmap.close?.(); } catch (_) {}
                        drawn = true;
                      } catch (e) {
                        if (window.__MCBAISE_DEBUG) console.debug('createImageBitmap failed', e);
                      }
                    }

                    // Try canvas.captureStream -> ImageCapture.grabFrame as a fallback (some browsers provide compositor frames)
                    if (!drawn && typeof t.canvas.captureStream === 'function' && typeof window.ImageCapture === 'function') {
                      try {
                        const stream = t.canvas.captureStream();
                        const track = (stream && stream.getVideoTracks && stream.getVideoTracks()[0]);
                        if (track) {
                          try {
                            const ic = new ImageCapture(track);
                            const frameBitmap = await ic.grabFrame();
                            try {
                              ctx.drawImage(frameBitmap, 0, 0, frameBitmap.width, frameBitmap.height, Math.round(r.left), Math.round(r.top), Math.round(r.width), Math.round(r.height));
                              drawn = true;
                            } finally {
                              try { frameBitmap.close?.(); } catch (_) {}
                            }
                          } catch (e) {
                            if (window.__MCBAISE_DEBUG) console.debug('ImageCapture.grabFrame failed', e);
                          } finally {
                            try { track.stop(); } catch (_) {}
                          }
                        }
                      } catch (e) {
                        if (window.__MCBAISE_DEBUG) console.debug('captureStream fallback failed', e);
                      }
                    }

                    if (!drawn) {
                      // Last resort: try direct draw (may be black for non-preserved WebGL canvases)
                      try {
                        ctx.drawImage(t.canvas, 0, 0, srcW, srcH, Math.round(r.left), Math.round(r.top), Math.round(r.width), Math.round(r.height));
                        drawn = true;
                      } catch (e) {
                        if (window.__MCBAISE_DEBUG) console.debug('direct drawImage fallback failed', e);
                      }
                    }
                  }
                } catch (e) {
                  if (window.__MCBAISE_DEBUG) console.debug('capture drawing flow error', e);
                }

                if (drawn) {
                  _drawnTargets += 1;
                } else {
                  _missingTarget = true;
                }
              } catch (e) {
                console.error('drawImage(target) failed', e);
                _missingTarget = true;
              }
            }

            // Expose a debug list so devs can inspect what's being captured.
            try { window._mcbaise_record_targets = targets.map(t => ({ rect: t.rect, fromIframe: !!t.fromIframe })); } catch (_) {}

            try {
              const dataUrl = composite.toDataURL('image/png');
              const len = dataUrl ? dataUrl.length : 0;
              if (window.__MCBAISE_DEBUG) console.debug('mcbaise:record:frame', { len, targets: (window._mcbaise_record_targets || []).length, drewPlaceholder: !!_drewExtraVizPlaceholder, missingTarget: !!_missingTarget, drawnTargets: _drawnTargets });

              // If we failed to draw any target at all (or missed at least one), treat
              // the frame as invalid and reuse last-good.
              if (_drawnTargets <= 0 || _missingTarget) {
                try { window._mcbaise_last_bad_frame = dataUrl; window._mcbaise_last_bad_reason = (_drawnTargets <= 0 ? 'no-targets-drawn' : 'missing-target'); } catch (_) {}
                if (lockstep) {
                  lockstepRetry = (lockstepRetry || 0) + 1;
                  if (lockstepRetry <= 50) {
                    if (window.__MCBAISE_DEBUG) console.warn('mcbaise:record:lockstep:missing-targets:retry', { frameIndex, retry: lockstepRetry, drawnTargets: _drawnTargets });
                    throw new Error('mcbaise_lockstep_retry');
                  }
                }
                if (lastGoodCompositeDataUrl) {
                  frames.push(lastGoodCompositeDataUrl);
                  frameIndex += 1;
                  if (lockstep) { lockstepRetry = 0; lockstepForcePause = false; lockstepFrameTimeSec = null; lockstepFrameSyncId = null; }
                  if (window.__MCBAISE_DEBUG) console.warn('mcbaise:record:using-last-good-composite-due-to-missing-targets', { len, drawnTargets: _drawnTargets });
                } else {
                  if (window.__MCBAISE_DEBUG) console.warn('mcbaise:record:skipping composite frame due to missing targets', { len, drawnTargets: _drawnTargets });
                }
              }
              // If we drew an EXTRA VIZ placeholder because a child didn't provide
              // a snapshot, prefer to reuse the last-good composite frame so the
              // output remains visually continuous. If no last-good exists, skip.
              else if (_drewExtraVizPlaceholder) {
                if (lockstep) {
                  lockstepRetry = (lockstepRetry || 0) + 1;
                  if (lockstepRetry <= 50) {
                    if (window.__MCBAISE_DEBUG) console.warn('mcbaise:record:lockstep:placeholder-drawn:retry', { frameIndex, retry: lockstepRetry });
                    throw new Error('mcbaise_lockstep_retry');
                  }
                }
                // Don't skip or freeze the whole composite just because an extra viz is missing.
                // Record the current composite (with placeholder or cached content) so time continues.
                if (len > 200) {
                  frames.push(dataUrl);
                  lastGoodCompositeDataUrl = dataUrl;
                  frameIndex += 1;
                  if (lockstep) { lockstepRetry = 0; lockstepForcePause = false; lockstepFrameTimeSec = null; lockstepFrameSyncId = null; }
                  if (window.__MCBAISE_DEBUG) console.warn('mcbaise:record:recording-frame-with-extra-viz-placeholder', { len });
                } else if (lastGoodCompositeDataUrl) {
                  frames.push(lastGoodCompositeDataUrl);
                  frameIndex += 1;
                  if (lockstep) { lockstepRetry = 0; lockstepForcePause = false; lockstepFrameTimeSec = null; lockstepFrameSyncId = null; }
                  if (window.__MCBAISE_DEBUG) console.warn('mcbaise:record:using-last-good-composite-due-to-tiny-placeholder-frame', { len });
                } else {
                  if (window.__MCBAISE_DEBUG) console.warn('mcbaise:record:skipping tiny placeholder frame', { len });
                }
              } else if (len > 200) {
                let isBlack = false;
                try {
                  isBlack = await (window.isMostlyBlackDataUrl ? window.isMostlyBlackDataUrl(dataUrl) : isMostlyBlackDataUrl(dataUrl));
                } catch (_) { isBlack = false; }

                if (isBlack) {
                  if (lockstep) {
                    lockstepRetry = (lockstepRetry || 0) + 1;
                    if (lockstepRetry <= 50) {
                      if (window.__MCBAISE_DEBUG) console.warn('mcbaise:record:lockstep:black-frame:retry', { frameIndex, retry: lockstepRetry });
                      throw new Error('mcbaise_lockstep_retry');
                    }
                  }
                  if (lastGoodCompositeDataUrl) {
                    frames.push(lastGoodCompositeDataUrl);
                    frameIndex += 1;
                    if (lockstep) { lockstepRetry = 0; lockstepForcePause = false; lockstepFrameTimeSec = null; lockstepFrameSyncId = null; }
                    if (window.__MCBAISE_DEBUG) console.warn('mcbaise:record:using-last-good-composite-due-to-black-frame', { len });
                  } else {
                    if (window.__MCBAISE_DEBUG) console.warn('mcbaise:record:skipping mostly-black composite frame', { len });
                  }
                } else {
                  frames.push(dataUrl);
                  lastGoodCompositeDataUrl = dataUrl;
                  frameIndex += 1;
                  if (lockstep) { lockstepRetry = 0; lockstepForcePause = false; lockstepFrameTimeSec = null; lockstepFrameSyncId = null; }
                }
              } else {
                if (lockstep) {
                  lockstepRetry = (lockstepRetry || 0) + 1;
                  if (lockstepRetry <= 50) {
                    if (window.__MCBAISE_DEBUG) console.warn('mcbaise:record:lockstep:tiny-frame:retry', { frameIndex, retry: lockstepRetry, len });
                    throw new Error('mcbaise_lockstep_retry');
                  }
                }
                if (lastGoodCompositeDataUrl) {
                  frames.push(lastGoodCompositeDataUrl);
                  frameIndex += 1;
                  if (lockstep) { lockstepRetry = 0; lockstepForcePause = false; lockstepFrameTimeSec = null; lockstepFrameSyncId = null; }
                  if (window.__MCBAISE_DEBUG) console.warn('mcbaise:record:using-last-good-composite-due-to-tiny-frame', { len });
                } else {
                  if (window.__MCBAISE_DEBUG) console.warn('mcbaise:record:skipping tiny/empty frame', { len });
                }
              }
            } catch (e) {
              console.error('mcbaise:record:toDataURL failed', e);
            }
          } catch (err) {
            if (lockstep && err && String(err.message || err).includes('mcbaise_lockstep_retry')) {
              try {
                if (!isFullscreenRecording) return;
                try { if (window._mcbaise_full_record_token !== loopToken) return; } catch (_) {}
                recordInterval = setTimeout(tick, 80);
                return;
              } catch (_) {}
            }
            console.error('Fullscreen capture tick failed', err);
          }

          try {
            if (!isFullscreenRecording) return;
            try { if (window._mcbaise_full_record_token !== loopToken) return; } catch (_) {}
            if (lockstep) {
              // Resume playback between lockstep barriers.
              try {
                const p = (typeof window !== 'undefined') ? window._mcbaise_player : null;
                try { p?.playVideo?.(); } catch (_) {}
              } catch (_) {}

              recordInterval = setTimeout(tick, intervalMs);
            } else {
              const nowMs2 = (typeof performance !== 'undefined' && performance.now) ? performance.now() : Date.now();
              const nextMs = startMs + frameIndex * intervalMs;
              const waitMs = Math.max(0, Math.round(nextMs - nowMs2));
              recordInterval = setTimeout(tick, waitMs);
            }
          } catch (_) {}
        };
        recordInterval = setTimeout(tick, 0);
      } else {
        // Stop recording and create GIF
        isFullscreenRecording = false;
        try { clearTimeout(recordInterval); } catch (_) { try { clearInterval(recordInterval); } catch (_) {} }
        try { window._mcbaise_full_record_token = null; } catch (_) {}
        try { _mcbaise_reset_canvas_capture_cache(); } catch (_) {}
        fullscreenIcon.textContent = 'web';
        fullscreenIcon.style.color = '#cccccc'; // Back to light grey
        if (frames.length > 0) createGIF(frames, { fps: _mcbaise_full_record_fps });
      }
    });

    function createGIF(frameDataURLs, opts) {
      const fps = Math.max(1, Math.min(60, Math.round(Number(opts && opts.fps) || 10)));
      const delayMs = Math.max(1, Math.round(1000 / fps));
      // Helper: fallback to WebM by replaying frames onto a canvas and recording via MediaRecorder
      function createWebMFromFrames(urls, fps = 10, hooks) {
        return new Promise(async (resolve, reject) => {
          try {
            if (!urls || !urls.length) return reject(new Error('no frames'));

            let cancelled = false;
            const onProgress = (hooks && typeof hooks.onProgress === 'function') ? hooks.onProgress : null;
            const onRegisterCancel = (hooks && typeof hooks.registerCancel === 'function') ? hooks.registerCancel : null;
            const cancel = () => {
              cancelled = true;
              try { clearInterval(id); } catch (_) {}
              try { recorder.stop(); } catch (_) {}
            };
            // Load all images
            const imgs = await Promise.all(urls.map(u => new Promise((res, rej) => {
              const im = new Image();
              im.onload = () => res(im);
              im.onerror = rej;
              im.src = u;
            })));

            const w = imgs[0].naturalWidth || imgs[0].width || 640;
            const h = imgs[0].naturalHeight || imgs[0].height || 480;
            const oc = document.createElement('canvas');
            oc.width = w; oc.height = h;
            const octx = oc.getContext('2d', { willReadFrequently: true });

            const stream = oc.captureStream(Math.max(1, fps));
            const recorder = new MediaRecorder(stream, { mimeType: 'video/webm;codecs=vp9' });
            const chunks = [];
            recorder.ondataavailable = (e) => { if (e.data && e.data.size) chunks.push(e.data); };
            recorder.onstop = () => {
              const blob = new Blob(chunks, { type: 'video/webm' });
              resolve(blob);
            };

            recorder.start();
            // Playback loop
            let idx = 0;
            const interval = Math.round(1000 / fps);
            let id = null;
            try { if (onRegisterCancel) onRegisterCancel(cancel); } catch (_) {}

            id = setInterval(() => {
              try {
                if (cancelled) return;
                const im = imgs[idx % imgs.length];
                octx.clearRect(0, 0, w, h);
                octx.drawImage(im, 0, 0, w, h);
                idx++;
                try { if (onProgress) onProgress(Math.min(1, idx / imgs.length)); } catch (_) {}
                if (idx >= imgs.length) {
                  clearInterval(id);
                  setTimeout(() => {
                    try { recorder.stop(); } catch (_) { }
                  }, 50);
                }
              } catch (e) { clearInterval(id); try { recorder.stop(); } catch (_) {} reject(e); }
            }, interval);
          } catch (e) { reject(e); }
        });
      }

      if (!frameDataURLs || frameDataURLs.length === 0) return;

      // If only one frame or gif.js is unreliable, prefer WebM fallback for reliability.
      if (frameDataURLs.length < 2) {
        createWebMFromFrames(frameDataURLs, fps).then(blob => {
          const url = URL.createObjectURL(blob);
          const a = document.createElement('a');
          a.href = url;
          a.download = getOutputFilename('webm');
          document.body.appendChild(a);
          a.click();
          document.body.removeChild(a);
          URL.revokeObjectURL(url);
        }).catch(e => console.error('webm fallback failed', e));
        return;
      }

      // Otherwise attempt GIF. No timeout: wait indefinitely.
      // If GIF rendering actually fails, retry twice, then fall back to WebM.
      const fallbackToWebm = (reason, err) => {
        try { console.warn('gif: falling back to webm', { reason, err }); } catch (_) {}
        _mcbaise_encode_active = true;
        _mcbaise_show_encode_overlay('Encoding WebM…', 'Rendering frames…', 0);
        let cancelled = false;
        _mcbaise_cancel_encode = (why) => {
          cancelled = true;
          try { if (typeof _mcbaise_cancel_encode._inner === 'function') _mcbaise_cancel_encode._inner(); } catch (_) {}
          _mcbaise_cancel_encode = null;
          _mcbaise_encode_active = false;
          _mcbaise_hide_encode_overlay();
          if (window.__MCBAISE_DEBUG) console.debug('mcbaise:encode:webm:cancelled', why);
        };

        createWebMFromFrames(frameDataURLs, fps, {
          onProgress: (p) => {
            if (cancelled) return;
            _mcbaise_show_encode_overlay('Encoding WebM…', `Progress ${Math.round((p || 0) * 100)}%`, p || 0);
          },
          registerCancel: (fn) => { try { _mcbaise_cancel_encode._inner = fn; } catch (_) {} },
        }).then(blob => {
          if (cancelled) return;
          const url = URL.createObjectURL(blob);
          const a = document.createElement('a');
          a.href = url;
          a.download = getOutputFilename('webm');
          document.body.appendChild(a);
          a.click();
          document.body.removeChild(a);
          URL.revokeObjectURL(url);
        }).catch(e => {
          if (!cancelled) console.error('webm fallback failed', e);
        }).finally(() => {
          if (cancelled) return;
          _mcbaise_cancel_encode = null;
          _mcbaise_encode_active = false;
          _mcbaise_hide_encode_overlay();
        });
      };

      (async () => {
        _mcbaise_encode_active = true;

        // Cancellation: if user clicks Stop, abort current attempt and exit (no fallback).
        let userCancelled = false;
        _mcbaise_cancel_encode = (why) => {
          userCancelled = true;
          try { if (typeof _mcbaise_cancel_encode._inner === 'function') _mcbaise_cancel_encode._inner(); } catch (_) {}
          _mcbaise_cancel_encode = null;
          _mcbaise_encode_active = false;
          _mcbaise_hide_encode_overlay();
          if (window.__MCBAISE_DEBUG) console.debug('mcbaise:encode:cancelled', why);
        };

        // Preload frames (show progress)
        const imgs = [];
        try {
          for (let i = 0; i < frameDataURLs.length; i++) {
            if (userCancelled) return;
            const u = frameDataURLs[i];
            _mcbaise_show_encode_overlay('Preparing GIF…', `Loading frame ${i + 1}/${frameDataURLs.length}`, (i / Math.max(1, frameDataURLs.length)) * 0.25);
            // eslint-disable-next-line no-await-in-loop
            const im = await new Promise((res, rej) => {
              const img = new Image();
              img.onload = () => res(img);
              img.onerror = rej;
              img.src = u;
            });
            imgs.push(im);
          }
        } catch (e) {
          if (!userCancelled) console.warn('gif: preload failed', e);
          if (!userCancelled) fallbackToWebm('preload_failed', e);
          return;
        }

        let attempt = 0;
        const MAX_ATTEMPTS = 2;

        const startAttempt = () => {
          if (userCancelled) return;
          attempt++;
          const gif = new GIF({ workers: 2, quality: 10, workerScript: 'gif.worker.js' });

          try { _mcbaise_cancel_encode._inner = () => { try { gif.abort?.(); } catch (_) {} }; } catch (_) {}

          try {
            for (const im of imgs) gif.addFrame(im, { delay: delayMs });
          } catch (e) {
            if (attempt < MAX_ATTEMPTS) {
              console.warn('gif: addFrame failed, retrying', { attempt, err: e });
              setTimeout(startAttempt, 0);
              return;
            }
            fallbackToWebm('addFrame_failed', e);
            return;
          }

          try {
            gif.on('progress', (p) => {
              if (userCancelled) return;
              const pp = Math.max(0, Math.min(1, Number(p) || 0));
              _mcbaise_show_encode_overlay(
                `Encoding GIF… (${attempt}/${MAX_ATTEMPTS})`,
                `Progress ${Math.round(pp * 100)}%`,
                0.25 + pp * 0.75
              );
            });
          } catch (_) {}

          try {
            gif.on('finished', function(blob) {
              if (userCancelled) return;
              _mcbaise_show_encode_overlay('Encoding GIF…', 'Finalizing…', 1);
              const url = URL.createObjectURL(blob);
              const a = document.createElement('a');
              a.href = url;
              a.download = getOutputFilename('gif');
              document.body.appendChild(a);
              a.click();
              document.body.removeChild(a);
              URL.revokeObjectURL(url);
              _mcbaise_cancel_encode = null;
              _mcbaise_encode_active = false;
              _mcbaise_hide_encode_overlay();
            });
          } catch (_) {}

          try {
            gif.on('abort', () => {
              if (userCancelled) return;
              // A non-user abort is treated as a failure.
              console.warn('gif: aborted');
              if (attempt < MAX_ATTEMPTS) {
                setTimeout(startAttempt, 0);
              } else {
                fallbackToWebm('abort', null);
              }
            });
          } catch (_) {}

          try {
            _mcbaise_show_encode_overlay(`Encoding GIF… (${attempt}/${MAX_ATTEMPTS})`, 'Starting…', 0.25);
            gif.render();
          } catch (e) {
            if (attempt < MAX_ATTEMPTS) {
              console.warn('gif.render threw, retrying', { attempt, err: e });
              setTimeout(startAttempt, 0);
            } else {
              fallbackToWebm('render_throw', e);
            }
          }
        };

        startAttempt();
      })();
    }
  </script>
</body>
</html>
